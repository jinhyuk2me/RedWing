# -*- coding: utf-8 -*-
"""
PDS TCN Data Preprocessor
MP4 ì˜ìƒì—ì„œ ìì„¸ ë°ì´í„° ì¶”ì¶œ ë° ì „ì²˜ë¦¬
"""

import cv2
import mediapipe as mp
import numpy as np
import os
import json
from pathlib import Path
from typing import List, Dict, Tuple, Optional
import logging
from config import DATA_CONFIG, MEDIAPIPE_CONFIG, GESTURE_CLASSES, PATHS

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PoseDataPreprocessor:
    """MP4 ì˜ìƒì—ì„œ ìì„¸ ë°ì´í„° ì¶”ì¶œ ë° ì „ì²˜ë¦¬"""
    
    def __init__(self):
        # MediaPipe ì„¤ì • (ê²½ê³  í•´ê²°ì„ ìœ„í•œ ê°œì„ ëœ ì„¤ì •)
        self.mp_pose = mp.solutions.pose
        self.pose = self.mp_pose.Pose(
            static_image_mode=False,
            model_complexity=1,
            enable_segmentation=False,
            smooth_landmarks=True,
            smooth_segmentation=True,
            min_detection_confidence=DATA_CONFIG['min_detection_confidence'],
            min_tracking_confidence=DATA_CONFIG['min_tracking_confidence']
        )
        
        # ì œìŠ¤ì²˜ í´ë˜ìŠ¤ ë§¤í•‘ (í´ë”ëª…ê³¼ ID ë§¤í•‘)
        self.gesture_classes = {v: k for k, v in GESTURE_CLASSES.items()}
        
        # MediaPipe ê´€ì ˆ ì¸ë±ìŠ¤
        self.key_landmarks = MEDIAPIPE_CONFIG['key_landmarks']
    
    def validate_paths(self) -> bool:
        """
        ê²½ë¡œ ê²€ì¦ ë° í•„ìš”í•œ í´ë” ìƒì„±
        
        Returns:
            bool: ëª¨ë“  ê²½ë¡œê°€ ìœ íš¨í•˜ë©´ True
        """
        logger.info("=== ê²½ë¡œ ê²€ì¦ ì‹œì‘ ===")
        
        # ì›ë³¸ ë°ì´í„° ê²½ë¡œ í™•ì¸
        raw_data_path = Path(PATHS['raw_data'])
        if not raw_data_path.exists():
            logger.error(f"âŒ ì›ë³¸ ë°ì´í„° í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {raw_data_path.absolute()}")
            return False
        
        logger.info(f"âœ… ì›ë³¸ ë°ì´í„° í´ë”: {raw_data_path.absolute()}")
        
        # ì œìŠ¤ì²˜ í´ë” í™•ì¸
        missing_gestures = []
        gesture_stats = {}
        
        for gesture_name in GESTURE_CLASSES.values():
            gesture_folder = raw_data_path / gesture_name
            if gesture_folder.exists():
                mp4_files = list(gesture_folder.glob("*.mp4"))
                gesture_stats[gesture_name] = len(mp4_files)
                logger.info(f"âœ… {gesture_name}: {len(mp4_files)}ê°œ ì˜ìƒ íŒŒì¼")
            else:
                missing_gestures.append(gesture_name)
                logger.warning(f"âŒ {gesture_name} í´ë” ì—†ìŒ: {gesture_folder}")
        
        if missing_gestures:
            logger.error(f"âŒ ëˆ„ë½ëœ ì œìŠ¤ì²˜ í´ë”ë“¤: {missing_gestures}")
            return False
        
        # ì²˜ë¦¬ëœ ë°ì´í„° ê²½ë¡œ ìƒì„±
        processed_data_path = Path(PATHS['processed_data'])
        if not processed_data_path.exists():
            logger.info(f"ğŸ“ ì²˜ë¦¬ëœ ë°ì´í„° í´ë” ìƒì„±: {processed_data_path.absolute()}")
            processed_data_path.mkdir(parents=True, exist_ok=True)
        else:
            logger.info(f"âœ… ì²˜ë¦¬ëœ ë°ì´í„° í´ë”: {processed_data_path.absolute()}")
        
        # ë¡œê·¸ í´ë” í™•ì¸
        logs_path = Path(PATHS['logs'])
        if not logs_path.exists():
            logs_path.mkdir(parents=True, exist_ok=True)
            logger.info(f"ğŸ“ ë¡œê·¸ í´ë” ìƒì„±: {logs_path.absolute()}")
        
        # ìš”ì•½ ì¶œë ¥
        total_videos = sum(gesture_stats.values())
        logger.info("=== ê²½ë¡œ ê²€ì¦ ì™„ë£Œ ===")
        logger.info(f"ğŸ“Š ì´ ì˜ìƒ íŒŒì¼: {total_videos}ê°œ")
        for gesture, count in gesture_stats.items():
            logger.info(f"   - {gesture}: {count}ê°œ")
        
        return True
    
    def cleanup_existing_data(self, output_root: str = None) -> bool:
        """
        ê¸°ì¡´ ì²˜ë¦¬ëœ ë°ì´í„° ì •ë¦¬
        
        Args:
            output_root: ì •ë¦¬í•  ë°ì´í„° í´ë” ê²½ë¡œ
            
        Returns:
            bool: ì •ë¦¬ ì„±ê³µì‹œ True
        """
        if output_root is None:
            output_root = PATHS['processed_data']
            
        output_path = Path(output_root)
        
        if not output_path.exists():
            logger.info(f"ğŸ†• ìƒˆë¡œìš´ ì²˜ë¦¬: {output_path.absolute()}")
            return True
        
        logger.info("ğŸ§¹ ê¸°ì¡´ ì²˜ë¦¬ëœ ë°ì´í„° ì •ë¦¬ ì‹œì‘...")
        logger.info(f"ğŸ“ ëŒ€ìƒ í´ë”: {output_path.absolute()}")
        
        try:
            # ê¸°ì¡´ .npy íŒŒì¼ë“¤ ì‚­ì œ
            npy_files = list(output_path.rglob("*.npy"))
            json_files = list(output_path.rglob("*.json"))
            
            total_files = len(npy_files) + len(json_files)
            
            if total_files == 0:
                logger.info("âœ… ì •ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return True
            
            logger.info(f"ğŸ—‘ï¸ ì‚­ì œí•  íŒŒì¼ë“¤:")
            logger.info(f"   - .npy íŒŒì¼: {len(npy_files)}ê°œ")
            logger.info(f"   - .json íŒŒì¼: {len(json_files)}ê°œ")
            logger.info(f"   - ì´ {total_files}ê°œ íŒŒì¼")
            
            # .npy íŒŒì¼ë“¤ ì‚­ì œ
            for npy_file in npy_files:
                npy_file.unlink()
                
            # .json íŒŒì¼ë“¤ ì‚­ì œ  
            for json_file in json_files:
                json_file.unlink()
            
            # ë¹ˆ í´ë”ë“¤ ì •ë¦¬
            for gesture_name in GESTURE_CLASSES.values():
                gesture_folder = output_path / gesture_name
                if gesture_folder.exists() and not any(gesture_folder.iterdir()):
                    gesture_folder.rmdir()
                    logger.info(f"ğŸ“‚ ë¹ˆ í´ë” ì‚­ì œ: {gesture_name}/")
            
            logger.info(f"âœ… ì •ë¦¬ ì™„ë£Œ: {total_files}ê°œ íŒŒì¼ ì‚­ì œ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ íŒŒì¼ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False
    
    def extract_pose_from_video(self, video_path: str) -> Optional[np.ndarray]:
        """
        MP4 ì˜ìƒì—ì„œ ìì„¸ ì¢Œí‘œ ì¶”ì¶œ
        
        Args:
            video_path: MP4 íŒŒì¼ ê²½ë¡œ
            
        Returns:
            shape: (frames, 17, 3) - 3D ì¢Œí‘œ (x, y, visibility)
        """
        try:
            cap = cv2.VideoCapture(video_path)
            
            if not cap.isOpened():
                logger.error(f"ì˜ìƒ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
                return None
                
            poses = []
            frame_count = 0
            max_frames = 600  # ìµœëŒ€ 20ì´ˆ (30fps * 20ì´ˆ) ì œí•œ
            
            while frame_count < max_frames:
                ret, frame = cap.read()
                if not ret:
                    break
                    
                # BGR -> RGB ë³€í™˜ (MediaPipe ê²½ê³  í•´ê²°ì„ ìœ„í•œ ì´ë¯¸ì§€ í¬ê¸° ì •ë³´ ì„¤ì •)
                height, width = frame.shape[:2]
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                rgb_frame.flags.writeable = False
                
                # ìì„¸ ê²€ì¶œ
                results = self.pose.process(rgb_frame)
                
                if results.pose_landmarks:
                    # 17ê°œ ì£¼ìš” ê´€ì ˆ ì¢Œí‘œ ì¶”ì¶œ
                    pose_data = []
                    for idx in self.key_landmarks:
                        landmark = results.pose_landmarks.landmark[idx]
                        pose_data.append([landmark.x, landmark.y, landmark.visibility])
                    
                    poses.append(pose_data)
                else:
                    # ìì„¸ ê²€ì¶œ ì‹¤íŒ¨ ì‹œ í•´ë‹¹ í”„ë ˆì„ ê±´ë„ˆë›°ê¸° (ëˆ„ì  ë°©ì§€)
                    logger.debug(f"ìì„¸ ê²€ì¶œ ì‹¤íŒ¨ - í”„ë ˆì„ {frame_count} ê±´ë„ˆë›°ê¸°")
                    continue
                
                frame_count += 1
                
            cap.release()
            
            if not poses:
                logger.warning(f"ìì„¸ë¥¼ ê²€ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
                return None
                
            poses_array = np.array(poses, dtype=np.float32)
            logger.info(f"ìì„¸ ì¶”ì¶œ ì™„ë£Œ: {video_path} -> {poses_array.shape}")
            
            return poses_array
            
        except Exception as e:
            logger.error(f"ìì„¸ ì¶”ì¶œ ì˜¤ë¥˜ ({video_path}): {e}")
            return None
    
    def normalize_pose_data(self, pose_data: np.ndarray) -> np.ndarray:
        """
        ìì„¸ ë°ì´í„° ì •ê·œí™”
        - ì¤‘ì‹¬ì (hip) ê¸°ì¤€ìœ¼ë¡œ ìƒëŒ€ ì¢Œí‘œ ë³€í™˜
        - ìŠ¤ì¼€ì¼ ì •ê·œí™”
        """
        if pose_data.shape[0] == 0:
            return pose_data
            
        normalized_poses = pose_data.copy()
        
        for frame_idx in range(pose_data.shape[0]):
            frame_pose = pose_data[frame_idx]
            
            # Hip ì¤‘ì‹¬ì  ê³„ì‚° (left_hip + right_hip) / 2
            left_hip = frame_pose[9]   # left_hip
            right_hip = frame_pose[10] # right_hip
            
            if left_hip[2] > 0.5 and right_hip[2] > 0.5:  # visibility ì²´í¬
                center = (left_hip[:2] + right_hip[:2]) / 2
                
                # ìƒëŒ€ ì¢Œí‘œë¡œ ë³€í™˜
                for joint_idx in range(len(self.key_landmarks)):
                    if frame_pose[joint_idx][2] > 0.5:  # visibility > 0.5
                        normalized_poses[frame_idx][joint_idx][:2] -= center
                
                # ìŠ¤ì¼€ì¼ ì •ê·œí™” (ì–´ê¹¨ ë„ˆë¹„ ê¸°ì¤€)
                left_shoulder = frame_pose[3]   # left_shoulder
                right_shoulder = frame_pose[4]  # right_shoulder
                
                if left_shoulder[2] > 0.5 and right_shoulder[2] > 0.5:
                    shoulder_width = np.linalg.norm(left_shoulder[:2] - right_shoulder[:2])
                    if shoulder_width > 0:
                        normalized_poses[frame_idx][:, :2] /= shoulder_width
        
        return normalized_poses
    
    def create_sliding_windows(self, pose_data: np.ndarray, window_size: int = None, stride: int = None) -> List[np.ndarray]:
        """
        ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ ì‹œê³„ì—´ ë°ì´í„° ìƒì„±
        """
        if window_size is None:
            window_size = DATA_CONFIG['window_size']
        if stride is None:
            stride = DATA_CONFIG['stride']
            
        if len(pose_data) < window_size:
            logger.warning(f"ì˜ìƒì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤ ({len(pose_data)} < {window_size})")
            return []
        
        windows = []
        for i in range(0, len(pose_data) - window_size + 1, stride):
            window = pose_data[i:i + window_size]
            windows.append(window)
            
        return windows
    
    def process_video_folder(self, input_folder: str, output_folder: str, gesture_name: str):
        """
        í´ë” ë‚´ ëª¨ë“  MP4 íŒŒì¼ ì²˜ë¦¬
        """
        input_path = Path(input_folder)
        output_path = Path(output_folder)
        output_path.mkdir(parents=True, exist_ok=True)
        
        gesture_id = self.gesture_classes.get(gesture_name, -1)
        if gesture_id == -1:
            logger.error(f"ì•Œ ìˆ˜ ì—†ëŠ” ì œìŠ¤ì²˜: {gesture_name}")
            return
        
        mp4_files = list(input_path.glob("*.mp4"))
        logger.info(f"{gesture_name} ì œìŠ¤ì²˜ ì²˜ë¦¬ ì‹œì‘: {len(mp4_files)}ê°œ íŒŒì¼")
        
        processed_count = 0
        for mp4_file in mp4_files:
            logger.info(f"ì²˜ë¦¬ ì¤‘: {mp4_file.name}")
            
            # ìì„¸ ì¶”ì¶œ
            pose_data = self.extract_pose_from_video(str(mp4_file))
            if pose_data is None:
                continue
                
            # ì •ê·œí™”
            normalized_pose = self.normalize_pose_data(pose_data)
            
            # ìŠ¬ë¼ì´ë”© ìœˆë„ìš°
            windows = self.create_sliding_windows(normalized_pose)
            
            # ê° ìœˆë„ìš°ë¥¼ ë³„ë„ íŒŒì¼ë¡œ ì €ì¥
            for window_idx, window_data in enumerate(windows):
                output_filename = f"{gesture_name}_{mp4_file.stem}_w{window_idx:03d}.npy"
                output_file_path = output_path / output_filename
                
                # ë°ì´í„° ì €ì¥ (x, y ì¢Œí‘œë§Œ ì‚¬ìš©)
                window_xy = window_data[:, :, :2]  # shape: (30, 17, 2)
                np.save(output_file_path, window_xy)
                
            processed_count += 1
            logger.info(f"ì™„ë£Œ: {mp4_file.name} -> {len(windows)}ê°œ ìœˆë„ìš°")
        
        logger.info(f"{gesture_name} ì œìŠ¤ì²˜ ì²˜ë¦¬ ì™„ë£Œ: {processed_count}/{len(mp4_files)}")
    
    def process_all_gestures(self, data_root: str = None, output_root: str = None):
        """
        ëª¨ë“  ì œìŠ¤ì²˜ í´ë” ì²˜ë¦¬
        """
        if data_root is None:
            data_root = PATHS['raw_data']
        if output_root is None:
            output_root = PATHS['processed_data']
        
        # ğŸ” ê²½ë¡œ ê²€ì¦ ë¨¼ì € ìˆ˜í–‰
        if not self.validate_paths():
            logger.error("âŒ ê²½ë¡œ ê²€ì¦ ì‹¤íŒ¨! ì²˜ë¦¬ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return
        
        # ğŸ§¹ ê¸°ì¡´ ë°ì´í„° ì •ë¦¬
        if not self.cleanup_existing_data(output_root):
            logger.error("âŒ ê¸°ì¡´ ë°ì´í„° ì •ë¦¬ ì‹¤íŒ¨! ì²˜ë¦¬ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return
            
        data_path = Path(data_root)
        logger.info(f"ğŸ¯ íšŒì „ëœ ì˜ìƒ ë°ì´í„° ì²˜ë¦¬ ì‹œì‘: {data_path.absolute()}")
        
        for gesture_name in GESTURE_CLASSES.values():
            gesture_folder = data_path / gesture_name
            
            if gesture_folder.exists():
                logger.info(f"=== {gesture_name.upper()} ì œìŠ¤ì²˜ ì²˜ë¦¬ ===")
                self.process_video_folder(
                    str(gesture_folder),
                    f"{output_root}/{gesture_name}",
                    gesture_name
                )
            else:
                logger.warning(f"í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {gesture_folder}")
    
    def create_dataset_summary(self, output_root: str = None):
        """
        ì²˜ë¦¬ëœ ë°ì´í„°ì…‹ ìš”ì•½ ì •ë³´ ìƒì„±
        """
        if output_root is None:
            output_root = PATHS['processed_data']
            
        output_path = Path(output_root)
        summary = {
            "total_samples": 0,
            "gestures": {}
        }
        
        for gesture_id, gesture_name in GESTURE_CLASSES.items():
            gesture_folder = output_path / gesture_name
            if gesture_folder.exists():
                npy_files = list(gesture_folder.glob("*.npy"))
                sample_count = len(npy_files)
                
                summary["gestures"][gesture_name] = {
                    "id": gesture_id,
                    "samples": sample_count,
                    "folder": str(gesture_folder)
                }
                summary["total_samples"] += sample_count
                logger.info(f"{gesture_name}: {sample_count}ê°œ ìƒ˜í”Œ")
        
        # ìš”ì•½ ì •ë³´ ì €ì¥
        summary_file = output_path / "dataset_summary.json"
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ë°ì´í„°ì…‹ ìš”ì•½: ì´ {summary['total_samples']}ê°œ ìƒ˜í”Œ")
        logger.info(f"ìš”ì•½ íŒŒì¼ ì €ì¥: {summary_file}")
        
        return summary

    @staticmethod
    def cleanup_only(output_root: str = None):
        """
        ì •ë¦¬ ì‘ì—…ë§Œ ìˆ˜í–‰í•˜ëŠ” ë…ë¦½ì ì¸ ë©”ì„œë“œ
        
        Args:
            output_root: ì •ë¦¬í•  ë°ì´í„° í´ë” ê²½ë¡œ
        """
        if output_root is None:
            output_root = PATHS['processed_data']
            
        logger.info("ğŸ§¹ ë°ì´í„° ì •ë¦¬ ëª¨ë“œ")
        logger.info("=" * 40)
        
        # ì„ì‹œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±í•˜ì—¬ ì •ë¦¬ ìˆ˜í–‰
        temp_preprocessor = PoseDataPreprocessor()
        
        if temp_preprocessor.cleanup_existing_data(output_root):
            logger.info("ğŸ‰ ì •ë¦¬ ì™„ë£Œ!")
        else:
            logger.error("âŒ ì •ë¦¬ ì‹¤íŒ¨!")

if __name__ == "__main__":
    import sys
    
    # ì •ë¦¬ ëª¨ë“œ ì²´í¬
    if len(sys.argv) > 1 and sys.argv[1] == "cleanup":
        # ğŸ§¹ ì •ë¦¬ ëª¨ë“œ
        PoseDataPreprocessor.cleanup_only()
    else:
        # ğŸ¯ íšŒì „ëœ ì˜ìƒ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘
        logger.info("ğŸ¯ PDS TCN ì „ì²˜ë¦¬ê¸° ì‹œì‘ - íšŒì „ëœ ì˜ìƒ ë°ì´í„° ì²˜ë¦¬")
        logger.info("=" * 60)
        logger.info("ğŸ’¡ ì •ë¦¬ë§Œ í•˜ë ¤ë©´: python preprocessor.py cleanup")
        logger.info("=" * 60)
        
        preprocessor = PoseDataPreprocessor()
        
        # ëª¨ë“  ì œìŠ¤ì²˜ ì²˜ë¦¬
        logger.info("ğŸ“¹ íšŒì „ëœ ì˜ìƒì—ì„œ ìì„¸ ë°ì´í„° ì¶”ì¶œ ì¤‘...")
        preprocessor.process_all_gestures()
        
        # ë°ì´í„°ì…‹ ìš”ì•½
        logger.info("ğŸ“Š ì²˜ë¦¬ëœ ë°ì´í„°ì…‹ ìš”ì•½ ìƒì„± ì¤‘...")
        summary = preprocessor.create_dataset_summary()
        
        if summary and summary['total_samples'] > 0:
            logger.info("ğŸ‰ ì „ì²˜ë¦¬ ì™„ë£Œ!")
            logger.info(f"âœ… ì´ {summary['total_samples']}ê°œ í•™ìŠµ ìƒ˜í”Œ ìƒì„±")
            logger.info("ğŸš€ ì´ì œ train.pyë¡œ ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
        else:
            logger.warning("âš ï¸ ì²˜ë¦¬ëœ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.") 