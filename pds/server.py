# -*- coding: utf-8 -*-
"""
Independent PDS TCP Server with Advanced Gesture Detection
Main Serverì™€ ì™„ì „ ë…ë¦½ì ì¸ PDS TCP ì„œë²„
"""

import socket
import threading
import json
import time
import logging
from typing import Dict, Optional, Callable
from datetime import datetime
import cv2
import numpy as np
import torch
import mediapipe as mp
from collections import deque
from pathlib import Path

from config import SERVER_CONFIG, GESTURE_CLASSES, TTS_MESSAGES, TCP_GESTURE_NAMES, IMPROVED_GESTURE_CONFIG, NETWORK_CONFIG, DEMO_VIDEO_CONFIG, MEDIAPIPE_CONFIG
from model import GestureModelManager
from utils import setup_logging

class SimpleGestureDetector:
    """create_visual_demo.pyì™€ ë™ì¼í•œ ê°„ë‹¨í•˜ê³  ì •í™•í•œ ì œìŠ¤ì²˜ ê²€ì¶œê¸°"""
    
    def __init__(self):
        self.logger = setup_logging()
        
        # MediaPipe ì´ˆê¸°í™”
        self.mp_pose = mp.solutions.pose
        self.pose = self.mp_pose.Pose(
            static_image_mode=False,
            model_complexity=1,
            enable_segmentation=False,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
        self.mp_drawing = mp.solutions.drawing_utils
        
        # ëª¨ë¸ ë¡œë“œ
        self.model_manager = GestureModelManager()
        self.model = self.model_manager.load_model()
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model.to(self.device)
        self.model.eval()
        
        # ìì„¸ ë²„í¼ (30í”„ë ˆì„)
        self.pose_buffer = deque(maxlen=30)
        self.key_landmarks = MEDIAPIPE_CONFIG['key_landmarks']
        
        self.logger.info("âœ… ê°„ë‹¨í•œ ì œìŠ¤ì²˜ ê²€ì¶œê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def extract_pose_landmarks(self, frame):
        """ìì„¸ ì¶”ì¶œ (create_visual_demo.pyì™€ ë™ì¼)"""
        height, width = frame.shape[:2]
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        rgb_frame.flags.writeable = False
        
        results = self.pose.process(rgb_frame)
        
        if results.pose_landmarks:
            pose_data = []
            for idx in self.key_landmarks:
                landmark = results.pose_landmarks.landmark[idx]
                pose_data.append([landmark.x, landmark.y, landmark.visibility])
            
            return np.array(pose_data, dtype=np.float32), results
        
        return None, results
    
    def normalize_pose_data(self, pose_data):
        """ì •ê·œí™” (create_visual_demo.pyì™€ ë™ì¼)"""
        if pose_data.shape[0] == 0:
            return pose_data
            
        normalized_pose = pose_data.copy()
        
        # Hip ì¤‘ì‹¬ì  ê³„ì‚°
        left_hip = pose_data[9]
        right_hip = pose_data[10]
        
        if left_hip[2] > 0.5 and right_hip[2] > 0.5:
            center = (left_hip[:2] + right_hip[:2]) / 2
            
            # ìƒëŒ€ ì¢Œí‘œë¡œ ë³€í™˜
            for joint_idx in range(len(self.key_landmarks)):
                if pose_data[joint_idx][2] > 0.5:
                    normalized_pose[joint_idx][:2] -= center
            
            # ìŠ¤ì¼€ì¼ ì •ê·œí™”
            left_shoulder = pose_data[3]
            right_shoulder = pose_data[4]
            
            if left_shoulder[2] > 0.5 and right_shoulder[2] > 0.5:
                shoulder_width = np.linalg.norm(left_shoulder[:2] - right_shoulder[:2])
                if shoulder_width > 0:
                    normalized_pose[:, :2] /= shoulder_width
        
        return normalized_pose
    
    def predict_gesture(self, pose_sequence):
        """ì œìŠ¤ì²˜ ì˜ˆì¸¡ (create_visual_demo.pyì™€ ë™ì¼)"""
        if len(pose_sequence) < 30:
            return None, 0.0
        
        # ìµœê·¼ 30í”„ë ˆì„ ì‚¬ìš©
        input_sequence = np.array(pose_sequence[-30:])  # (30, 17, 3)
        input_sequence = input_sequence[:, :, :2]  # (30, 17, 2) - x,yë§Œ
        input_sequence = input_sequence.reshape(input_sequence.shape[0], -1)  # (30, 34)
        
        # ì˜ˆì¸¡
        input_tensor = torch.FloatTensor(input_sequence).unsqueeze(0).to(self.device)
        
        with torch.no_grad():
            output = self.model(input_tensor)
            probabilities = torch.softmax(output, dim=1)
            confidence, predicted_class = torch.max(probabilities, 1)
            
            predicted_gesture = GESTURE_CLASSES[predicted_class.item()]
            confidence_score = confidence.item()
        
        return predicted_gesture, confidence_score
    
    def process_frame(self, frame):
        """í”„ë ˆì„ ì²˜ë¦¬ (create_visual_demo.py ë°©ì‹)"""
        # ìì„¸ ì¶”ì •
        pose_data, pose_results = self.extract_pose_landmarks(frame)
        
        prediction = None
        confidence = 0.0
        
        if pose_data is not None:
            normalized_pose = self.normalize_pose_data(pose_data)
            self.pose_buffer.append(normalized_pose)
            
            if len(self.pose_buffer) == 30:
                prediction, confidence = self.predict_gesture(list(self.pose_buffer))
        
        debug_info = {
            'gesture_completed': True,  # ê°„ë‹¨í™”
            'motion_duration': 2.0,
            'consistency_info': {
                'consistent_gesture': prediction,
                'consistency_score': confidence if prediction else 0
            },
            'confidence_trend': {
                'is_stable_increasing': True
            },
            'pose_results': pose_results
        }
        
        return frame, prediction, confidence, debug_info

class IndependentPDSServer:
    """Main Serverì™€ ì™„ì „ ë…ë¦½ì ì¸ PDS TCP ì„œë²„"""
    
    def __init__(self, gesture_callback: Optional[Callable] = None):
        self.logger = logging.getLogger(__name__)
        
        # ğŸ¯ ë…ë¦½ì  ì„œë²„ ì„¤ì •
        self.host = SERVER_CONFIG['host']
        self.port = SERVER_CONFIG['port']
        self.redwing_host = SERVER_CONFIG['redwing_host']
        self.redwing_port = SERVER_CONFIG['redwing_port']
        
        # ì†Œì¼“ë“¤
        self.server_socket = None
        self.redwing_socket = None
        
        # ìƒíƒœ
        self.is_running = False
        self.marshaling_active = False
        self.redwing_connected = False
        
        # í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ê´€ë¦¬
        self.clients = []
        
        # ğŸ¯ ê°„ë‹¨í•˜ê³  ì •í™•í•œ ì œìŠ¤ì²˜ ê²€ì¶œê¸° ì‚¬ìš©
        self.pose_detector = SimpleGestureDetector()
        self.gesture_callback = gesture_callback
        
        # ì œìŠ¤ì²˜ ì´ë²¤íŠ¸ ê´€ë¦¬
        self.last_gesture = None
        self.last_gesture_time = 0
        self.gesture_cooldown = 3.0
        
        # ê°„ë‹¨í•œ ì œìŠ¤ì²˜ í™•ì‹ ë„ ê´€ë¦¬
        self.gesture_confirmation = {
            'current_gesture': None,
            'confirmation_count': 0,
            'required_confirmations': 30,  # 30í”„ë ˆì„ ì—°ì† (ì•½ 1ì´ˆ, 30fps ê¸°ì¤€)
            'confidence_threshold': 0.9,   # ì„ê³„ê°’: 90%
        }
        
        # í™•ì‹ ë„ ì´ë ¥ ì¶”ì 
        self.confirmation_history = []
        
        # ì¹´ë©”ë¼ ê°ì²´ ì¬ì‚¬ìš©ì„ ìœ„í•œ ë©¤ë²„ ë³€ìˆ˜
        self.camera_cap = None
        self.camera_index = None
        
        # ğŸ¬ ë°ëª¨ ì˜ìƒ ê´€ë ¨ ë³€ìˆ˜
        self.demo_mode = DEMO_VIDEO_CONFIG['enabled']
        self.demo_videos = []
        self.current_demo_video_index = 0
        self.demo_gesture_index = 0
        self.demo_video_in_gesture = 0
        
        # ğŸ¬ ë°ëª¨ ì˜ìƒ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´
        self.demo_segments = []
        self.current_frame_idx = 0
        
        # ìƒ‰ìƒ ì •ì˜ (create_visual_demo.pyì™€ ë™ì¼)
        self.colors = {
            'stop': (0, 0, 255),      # Red
            'forward': (0, 255, 0),   # Green  
            'left': (255, 0, 0),      # Blue
            'right': (0, 255, 255),   # Yellow
            'background': (0, 0, 0),   # Black
            'text': (255, 255, 255),   # White
            'skeleton': (255, 128, 0)  # Orange
        }
        
        self.logger.info(f"ğŸ¯ ë…ë¦½ì  PDS ì„œë²„ ì´ˆê¸°í™”: {self.host}:{self.port}")

    def _initialize_camera(self):
        """ì¹´ë©”ë¼ ë˜ëŠ” ë°ëª¨ ì˜ìƒ ì´ˆê¸°í™”"""
        if self.demo_mode:
            return self._initialize_demo_video()
        else:
            # ì‹¤ì œ ì¹´ë©”ë¼ ì´ˆê¸°í™” (í•„ìš”ì‹œ)
            import cv2
            for camera_index in [0, 1, 2]:
                try:
                    cap = cv2.VideoCapture(camera_index)
                    if cap.isOpened():
                        ret, frame = cap.read()
                        if ret and frame is not None:
                            self.logger.info(f"âœ… ì¹´ë©”ë¼ {camera_index} ì´ˆê¸°í™” ì„±ê³µ")
                            return cap
                    cap.release()
                except Exception as e:
                    self.logger.warning(f"ì¹´ë©”ë¼ {camera_index} ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return None

    def _auto_rotate_frame(self, frame):
        """GUIì—ì„œ ì˜¬ë°”ë¥¸ ë°©í–¥ìœ¼ë¡œ ë³´ì´ë„ë¡ íšŒì „ ì¡°ì •"""
        if frame is None:
            return frame
        
        # pose_data_rotatedë¡œ ë§Œë“  ë°ëª¨ëŠ” ì´ë¯¸ ì˜¬ë°”ë¥¸ ë°©í–¥ì´ë¯€ë¡œ ì¶”ê°€ íšŒì „ ë¶ˆí•„ìš”
        return frame

    def _send_improved_gesture_event(self, gesture: str, confidence: float, debug_info: Dict):
        """ì œìŠ¤ì²˜ ì´ë²¤íŠ¸ ì†¡ì‹ """
        # ë‚´ë¶€ ì œìŠ¤ì²˜ëª…ì„ TCP í†µì‹ ìš© ëŒ€ë¬¸ìë¡œ ë³€í™˜
        tcp_gesture = TCP_GESTURE_NAMES.get(gesture, gesture.upper())
        
        event = {
            "type": "event",
            "event": "MARSHALING_GESTURE_DETECTED",
            "result": tcp_gesture,
            "confidence": confidence
        }
        
        # RedWing GUI Serverë¡œ ì „ì†¡
        if self.redwing_connected:
            self._send_to_redwing(event)
        
        # ì—°ê²°ëœ í´ë¼ì´ì–¸íŠ¸ë“¤ì—ê²Œë„ ì „ì†¡
        self._broadcast_to_clients(event)
        
        self.logger.info(f"ğŸ¯ ì œìŠ¤ì²˜ ì´ë²¤íŠ¸ ì†¡ì‹ : {tcp_gesture} (ì‹ ë¢°ë„: {confidence:.2f})")

    def start_server(self):
        """ë…ë¦½ì  ì„œë²„ ì‹œì‘"""
        try:
            self.is_running = True
            
            # PDS ëª…ë ¹ ìˆ˜ì‹  ì„œë²„ ì‹œì‘
            self._start_command_server()
            
            # RedWing GUI Server ì—°ê²° ì‹œì‘
            self._start_redwing_connection()
            
            # RedWing GUIì—ì„œ ë§ˆìƒ¬ë§ ì œì–´í•˜ë„ë¡ ëŒ€ê¸° ìƒíƒœë¡œ ì‹œì‘
            self._show_initial_gui()
            
            self.logger.info("ğŸ¯ ë…ë¦½ì  PDS TCP ì„œë²„ ì‹œì‘ ì™„ë£Œ (Main Serverì™€ ë¬´ê´€)")
            
        except Exception as e:
            self.logger.error(f"ì„œë²„ ì‹œì‘ ì‹¤íŒ¨: {e}")
            self.stop_server()

    def stop_server(self):
        """ì„œë²„ ì¤‘ì§€"""
        self.is_running = False
        self.marshaling_active = False
        
        # ì¹´ë©”ë¼ í•´ì œ
        if self.camera_cap:
            self.camera_cap.release()
            self.camera_cap = None
        
        # OpenCV ìœˆë„ìš° í•´ì œ
        try:
            cv2.destroyAllWindows()
        except:
            pass
        
        self.logger.info("ë…ë¦½ì  PDS TCP ì„œë²„ ì¤‘ì§€")

    def _start_marshaling(self):
        """ë§ˆìƒ¬ë§ ì‹œì‘"""
        if self.marshaling_active:
            self.logger.warning("âš ï¸ ë§ˆìƒ¬ë§ì´ ì´ë¯¸ í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤")
            return
        
        self.marshaling_active = True
        self.logger.info("ğŸ¯ ë§ˆìƒ¬ë§ ì‹œì‘")
        
        # ì œìŠ¤ì²˜ í™•ì‹ ë„ ìƒíƒœ ë¦¬ì…‹
        self.gesture_confirmation = {
            'current_gesture': None,
            'confirmation_count': 0,
            'required_confirmations': 30,
            'confidence_threshold': 0.9,
        }
        
        return True

    def _stop_marshaling(self):
        """ë§ˆìƒ¬ë§ ì¤‘ì§€"""
        if not self.marshaling_active:
            self.logger.warning("âš ï¸ ë§ˆìƒ¬ë§ì´ ì´ë¯¸ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤")
            return
        
        self.marshaling_active = False
        self.logger.info("ğŸ›‘ ë§ˆìƒ¬ë§ ì¤‘ì§€")
        return True

    def _show_initial_gui(self):
        """í†µí•© GUI ìŠ¤ë ˆë“œ ì‹œì‘"""
        import threading
        
        # í†µí•© GUI ê´€ë¦¬ ìŠ¤ë ˆë“œ ì‹œì‘
        gui_thread = threading.Thread(target=self._unified_gui_loop, daemon=True)
        gui_thread.start()
        self.logger.info("âœ… í†µí•© GUI ìŠ¤ë ˆë“œ ì‹œì‘")

    def _start_command_server(self):
        """PDS ëª…ë ¹ ìˆ˜ì‹  ì„œë²„ ì‹œì‘"""
        self.server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        self.server_socket.bind((self.host, self.port))
        self.server_socket.listen(SERVER_CONFIG['max_clients'])
        
        self.logger.info(f"PDS ëª…ë ¹ ìˆ˜ì‹  ì„œë²„ ì‹œì‘: {self.host}:{self.port}")
        
        # ëª…ë ¹ ìˆ˜ì‹  ìŠ¤ë ˆë“œ
        command_thread = threading.Thread(target=self._handle_commands, daemon=True)
        command_thread.start()

    def _start_redwing_connection(self):
        """RedWing GUI Server ì—°ê²° ì‹œì‘"""
        if SERVER_CONFIG.get('auto_connect_redwing', True):
            redwing_thread = threading.Thread(target=self._connect_to_redwing, daemon=True)
            redwing_thread.start()

    def _connect_to_redwing(self):
        """RedWing GUI Serverì— ì—°ê²°"""
        max_retries = NETWORK_CONFIG['redwing_connect_retries']
        retry_delay = NETWORK_CONFIG['redwing_connect_delay']
        
        for attempt in range(max_retries):
            try:
                self.redwing_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                self.redwing_socket.settimeout(NETWORK_CONFIG['connection_timeout'])
                self.redwing_socket.connect((self.redwing_host, self.redwing_port))
                
                # ì—°ê²° í›„ timeout ì œê±° (blocking ëª¨ë“œë¡œ ë³€ê²½)
                self.redwing_socket.settimeout(None)
                
                self.redwing_connected = True
                self.logger.info(f"âœ… RedWing GUI Server ì—°ê²° ì„±ê³µ: {self.redwing_host}:{self.redwing_port}")
                
                # ì—°ê²° í™•ì¸ ë©”ì‹œì§€ ì „ì†¡
                self._send_to_redwing({
                    "type": "system",
                    "message": "PDS_SERVER_CONNECTED",
                    "server_info": {
                        "host": self.host,
                        "port": self.port,
                        "capabilities": ["gesture_recognition", "marshaling_detection"]
                    }
                })
                
                # ì—°ê²° ìœ ì§€ ìŠ¤ë ˆë“œ ì‹œì‘
                heartbeat_thread = threading.Thread(target=self._heartbeat_loop, daemon=True)
                heartbeat_thread.start()
                
                # RedWing ë©”ì‹œì§€ ìˆ˜ì‹  ìŠ¤ë ˆë“œ ì‹œì‘
                redwing_message_thread = threading.Thread(target=self._handle_redwing_messages, daemon=True)
                redwing_message_thread.start()
                
                break
                
            except Exception as e:
                self.logger.warning(f"RedWing ì—°ê²° ì‹¤íŒ¨ ({attempt+1}/{max_retries}): {e}")
                if self.redwing_socket:
                    try:
                        self.redwing_socket.close()
                    except:
                        pass
                    self.redwing_socket = None
                
                if attempt < max_retries - 1:
                    time.sleep(retry_delay)
                else:
                    self.logger.error("RedWing GUI Server ì—°ê²° í¬ê¸° - ë…ë¦½ì  ëª¨ë“œë¡œ ê³„ì† ì‹¤í–‰")
                    self.redwing_connected = False

    def _heartbeat_loop(self):
        """RedWing ì—°ê²° ìœ ì§€"""
        while self.is_running and self.redwing_connected:
            try:
                time.sleep(NETWORK_CONFIG['heartbeat_interval'])
                
                if self.redwing_socket and self.redwing_connected:
                    heartbeat = {
                        "type": "heartbeat",
                        "timestamp": datetime.now().isoformat(),
                        "status": "active" if self.marshaling_active else "standby"
                    }
                    self._send_to_redwing(heartbeat)
                
            except Exception as e:
                self.logger.warning(f"í•˜íŠ¸ë¹„íŠ¸ ì „ì†¡ ì‹¤íŒ¨: {e}")
                self.redwing_connected = False
                # ì¬ì—°ê²° ì‹œë„
                if NETWORK_CONFIG.get('reconnect_on_failure', True):
                    self._connect_to_redwing()
                break

    def _handle_commands(self):
        """ëª…ë ¹ ì²˜ë¦¬ ìŠ¤ë ˆë“œ"""
        while self.is_running:
            try:
                client_socket, address = self.server_socket.accept()
                self.logger.info(f"í´ë¼ì´ì–¸íŠ¸ ì—°ê²°: {address}")
                
                self.clients.append(client_socket)
                
                # í´ë¼ì´ì–¸íŠ¸ ì²˜ë¦¬ ìŠ¤ë ˆë“œ
                client_thread = threading.Thread(
                    target=self._handle_client, 
                    args=(client_socket, address),
                    daemon=True
                )
                client_thread.start()
                
            except Exception as e:
                if self.is_running:
                    self.logger.error(f"í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

    def _handle_client(self, client_socket, address):
        """ê°œë³„ í´ë¼ì´ì–¸íŠ¸ ì²˜ë¦¬"""
        buffer = ""
        
        try:
            while self.is_running:
                data = client_socket.recv(SERVER_CONFIG['buffer_size']).decode('utf-8')
                if not data:
                    break
                
                buffer += data
                
                # ê°œí–‰ ë¬¸ìë¡œ ë©”ì‹œì§€ ë¶„í• 
                while '\n' in buffer:
                    message, buffer = buffer.split('\n', 1)
                    if message.strip():
                        self._process_command(message.strip(), client_socket)
                        
        except Exception as e:
            self.logger.error(f"í´ë¼ì´ì–¸íŠ¸ ì²˜ë¦¬ ì˜¤ë¥˜ {address}: {e}")
        finally:
            client_socket.close()
            if client_socket in self.clients:
                self.clients.remove(client_socket)
            self.logger.info(f"í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì¢…ë£Œ: {address}")

    def _process_command(self, message: str, client_socket):
        """ëª…ë ¹ ì²˜ë¦¬"""
        try:
            command_data = json.loads(message)
            command_type = command_data.get('type')
            command = command_data.get('command')
            
            self.logger.info(f"ëª…ë ¹ ìˆ˜ì‹ : {command_data}")
            
            if command_type == 'command':
                if command == 'MARSHALING_START':
                    self._start_marshaling()
                    self._send_response(client_socket, "MARSHALING_RECOGNITION_ACTIVATED")
                elif command == 'MARSHALING_STOP':
                    self._stop_marshaling()
                    self._send_response(client_socket, "MARSHALING_RECOGNITION_DEACTIVATED")
                elif command == 'STATUS':
                    self._send_status(client_socket)
                else:
                    self.logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹: {command}")
                    self._send_response(client_socket, "UNKNOWN_COMMAND")
                    
        except json.JSONDecodeError as e:
            self.logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            self._send_response(client_socket, "INVALID_JSON")
        except Exception as e:
            self.logger.error(f"ëª…ë ¹ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            self._send_response(client_socket, "PROCESSING_ERROR")

    def _send_response(self, client_socket, response_text: str):
        """í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì‘ë‹µ ì „ì†¡"""
        try:
            response = {
                "type": "response",
                "response": response_text,
                "timestamp": datetime.now().isoformat()
            }
            message = json.dumps(response) + '\n'
            client_socket.send(message.encode('utf-8'))
        except Exception as e:
            self.logger.error(f"ì‘ë‹µ ì „ì†¡ ì˜¤ë¥˜: {e}")

    def _send_status(self, client_socket):
        """ìƒíƒœ ì •ë³´ ì „ì†¡"""
        status = {
            "type": "status",
            "server_info": {
                "host": self.host,
                "port": self.port,
                "running": self.is_running,
                "marshaling_active": self.marshaling_active,
                "redwing_connected": self.redwing_connected,
                "connected_clients": len(self.clients)
            },
            "gesture_info": {
                "last_gesture": self.last_gesture,
                "confirmation_count": self.gesture_confirmation['confirmation_count'],
                "confidence_threshold": self.gesture_confirmation['confidence_threshold']
            },
            "timestamp": datetime.now().isoformat()
        }
        
        try:
            message = json.dumps(status) + '\n'
            client_socket.send(message.encode('utf-8'))
        except Exception as e:
            self.logger.error(f"ìƒíƒœ ì „ì†¡ ì˜¤ë¥˜: {e}")

    def _handle_redwing_messages(self):
        """RedWing GUI Serverë¡œë¶€í„° ë©”ì‹œì§€ ìˆ˜ì‹  ì²˜ë¦¬"""
        buffer = ""
        
        self.logger.info("ğŸ”„ RedWing ë©”ì‹œì§€ ìˆ˜ì‹  ìŠ¤ë ˆë“œ ì‹œì‘")
        
        while self.is_running and self.redwing_connected:
            try:
                if not self.redwing_socket:
                    break
                
                # RedWingìœ¼ë¡œë¶€í„° ë©”ì‹œì§€ ìˆ˜ì‹ 
                data = self.redwing_socket.recv(SERVER_CONFIG['buffer_size']).decode('utf-8')
                if not data:
                    self.logger.warning("RedWing ì—°ê²°ì´ ì¢…ë£Œë¨")
                    break
                
                buffer += data
                
                # ê°œí–‰ ë¬¸ìë¡œ ë©”ì‹œì§€ ë¶„í• 
                while '\n' in buffer:
                    message, buffer = buffer.split('\n', 1)
                    if message.strip():
                        self.logger.info(f"ğŸ“¨ RedWing ë©”ì‹œì§€ ìˆ˜ì‹ : {message.strip()}")
                        self._process_redwing_message(message.strip())
                        
            except Exception as e:
                if self.is_running and self.redwing_connected:
                    self.logger.error(f"RedWing ë©”ì‹œì§€ ìˆ˜ì‹  ì˜¤ë¥˜: {e}")
                break
        
        self.redwing_connected = False
        self.logger.info("RedWing ë©”ì‹œì§€ ìˆ˜ì‹  ìŠ¤ë ˆë“œ ì¢…ë£Œ")

    def _process_redwing_message(self, message: str):
        """RedWingìœ¼ë¡œë¶€í„° ë°›ì€ ë©”ì‹œì§€ ì²˜ë¦¬"""
        try:
            message_data = json.loads(message)
            message_type = message_data.get('type')
            
            self.logger.info(f"ğŸ“¡ RedWing ë©”ì‹œì§€ ì²˜ë¦¬: {message_data}")
            
            if message_type == 'command':
                command = message_data.get('command')
                
                if command == 'MARSHALING_START':
                    self.logger.info("ğŸ¯ RedWingìœ¼ë¡œë¶€í„° ë§ˆìƒ¬ë§ ì‹œì‘ ëª…ë ¹ ìˆ˜ì‹ ")
                    self._start_marshaling()
                elif command == 'MARSHALING_STOP':
                    self.logger.info("ğŸ›‘ RedWingìœ¼ë¡œë¶€í„° ë§ˆìƒ¬ë§ ì¤‘ì§€ ëª…ë ¹ ìˆ˜ì‹ ")
                    self._stop_marshaling()
                elif command == 'STATUS':
                    self.logger.info("ğŸ“Š RedWingìœ¼ë¡œë¶€í„° ìƒíƒœ ì¡°íšŒ ëª…ë ¹ ìˆ˜ì‹ ")
                    # ìƒíƒœ ì •ë³´ë¥¼ RedWingì— ì‘ë‹µ
                    self._send_status_to_redwing()
                else:
                    self.logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” RedWing ëª…ë ¹: {command}")
            else:
                self.logger.info(f"ê¸°íƒ€ RedWing ë©”ì‹œì§€ íƒ€ì…: {message_type}")
                
        except json.JSONDecodeError as e:
            self.logger.error(f"RedWing ë©”ì‹œì§€ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        except Exception as e:
            self.logger.error(f"RedWing ë©”ì‹œì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

    def _send_status_to_redwing(self):
        """RedWingì— ìƒíƒœ ì •ë³´ ì „ì†¡"""
        status = {
            "type": "status_response",
            "server_info": {
                "host": self.host,
                "port": self.port,
                "running": self.is_running,
                "marshaling_active": self.marshaling_active,
                "redwing_connected": self.redwing_connected,
                "connected_clients": len(self.clients)
            },
            "gesture_info": {
                "last_gesture": self.last_gesture,
                "confirmation_count": self.gesture_confirmation['confirmation_count'],
                "confidence_threshold": self.gesture_confirmation['confidence_threshold']
            },
            "timestamp": datetime.now().isoformat()
        }
        
        self._send_to_redwing(status)

    def _send_to_redwing(self, data: Dict):
        """RedWing GUI Serverì— ë°ì´í„° ì†¡ì‹ """
        if not self.redwing_socket or not self.redwing_connected:
            return False
        
        try:
            message = json.dumps(data, ensure_ascii=False) + '\n'
            self.redwing_socket.send(message.encode('utf-8'))
            return True
            
        except Exception as e:
            self.logger.error(f"RedWing ì†¡ì‹  ì˜¤ë¥˜: {e}")
            self.redwing_connected = False
            self.redwing_socket = None
            # ì¬ì—°ê²° ì‹œë„
            if NETWORK_CONFIG.get('reconnect_on_failure', True):
                self._connect_to_redwing()
            return False

    def _broadcast_to_clients(self, data: Dict):
        """ì—°ê²°ëœ ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ë¸Œë¡œë“œìºìŠ¤íŠ¸"""
        if not self.clients:
            return
        
        message = json.dumps(data, ensure_ascii=False) + '\n'
        
        for client in list(self.clients):  # ë¦¬ìŠ¤íŠ¸ ë³µì‚¬ë¡œ ì•ˆì „í•˜ê²Œ ìˆœíšŒ
            try:
                client.send(message.encode('utf-8'))
            except Exception as e:
                self.logger.warning(f"í´ë¼ì´ì–¸íŠ¸ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                if client in self.clients:
                    self.clients.remove(client)
                try:
                    client.close()
                except:
                    pass

    def _prepare_demo_videos(self):
        """ë°ëª¨ ì˜ìƒ ì¤€ë¹„ - concatenated_demo íŒŒì¼ ì‚¬ìš©"""
        demo_dir = Path('demo_videos')
        if not demo_dir.exists():
            self.logger.warning("âš ï¸ demo_videos í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤")
            return
        
        # ì›ë³¸ concatenated_demo íŒŒì¼ ì°¾ê¸° (_predictions ì œì™¸)
        demo_files = []
        for file in demo_dir.glob('concatenated_demo_*.mp4'):
            # _predictions.mp4 íŒŒì¼ì€ ì œì™¸ (ì´ë¯¸ ì˜ˆì¸¡ì´ í¬í•¨ëœ ìµœì¢… ì˜ìƒ)
            if not file.name.endswith('_predictions.mp4'):
                demo_files.append(file)
        
        if not demo_files:
            self.logger.warning("âš ï¸ ì›ë³¸ concatenated_demo íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            return
        
        # ê°€ì¥ ìµœê·¼ ì›ë³¸ íŒŒì¼
        latest_demo = sorted(demo_files)[-1]
        segments_file = str(latest_demo).replace('.mp4', '_segments.json')
        
        if not Path(segments_file).exists():
            self.logger.warning(f"âš ï¸ ì„¸ê·¸ë¨¼íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {segments_file}")
            return
        
        # ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ ë¡œë“œ
        with open(segments_file, 'r', encoding='utf-8') as f:
            self.demo_segments = json.load(f)
        
        self.demo_videos = [{'path': str(latest_demo), 'segments': self.demo_segments}]
        self.logger.info(f"ğŸ¬ ë°ëª¨ ì˜ìƒ ì¤€ë¹„ ì™„ë£Œ: {latest_demo.name}")
        self.logger.info(f"ğŸ“Š ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜: {len(self.demo_segments)}ê°œ")

    def _initialize_demo_video(self):
        """ë°ëª¨ ì˜ìƒ ì´ˆê¸°í™”"""
        import cv2
        
        # ë°ëª¨ ì˜ìƒ ì¤€ë¹„
        if not self.demo_videos:
            self._prepare_demo_videos()
        
        if not self.demo_videos:
            self.logger.error("âŒ ë°ëª¨ ì˜ìƒ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            return None
        
        # ë°ëª¨ ì˜ìƒ íŒŒì¼ ì—´ê¸°
        demo_video = self.demo_videos[0]
        cap = cv2.VideoCapture(demo_video['path'])
        
        if not cap.isOpened():
            self.logger.error(f"âŒ ë°ëª¨ ì˜ìƒ ì—´ê¸° ì‹¤íŒ¨: {demo_video['path']}")
            return None
        
        self.current_frame_idx = 0
        self.logger.info(f"ğŸ¬ ë°ëª¨ ì˜ìƒ ì‹œì‘: {demo_video['path']}")
        return cap

    def _get_current_ground_truth(self):
        """í˜„ì¬ í”„ë ˆì„ì˜ ground truth ì œìŠ¤ì²˜ ë°˜í™˜"""
        if not self.demo_segments:
            return None
        
        for segment in self.demo_segments:
            if segment['start_frame'] <= self.current_frame_idx <= segment['end_frame']:
                return segment['gesture']
        
        return None

    def _draw_enhanced_gui_overlay_rotated(self, frame, gesture, confidence, debug_info, frame_count):
        """íšŒì „ëœ í”„ë ˆì„ì— ë§ëŠ” ì˜¤ë²„ë ˆì´ (create_visual_demo.py ìŠ¤íƒ€ì¼)"""
        if frame is None:
            return frame
        
        height, width = frame.shape[:2]  # ì´ë¯¸ íšŒì „ëœ í”„ë ˆì„ì˜ í¬ê¸°
        
        # í˜„ì¬ ground truth ê°€ì ¸ì˜¤ê¸°
        gt_gesture = self._get_current_ground_truth() if self.demo_mode else None
        
        # ë°˜íˆ¬ëª… ì˜¤ë²„ë ˆì´ íŒ¨ë„ ìƒì„±
        overlay = frame.copy()
        
        # ìƒë‹¨ ì •ë³´ íŒ¨ë„ (ë°˜íˆ¬ëª… ê²€ì€ ë°°ê²½)
        cv2.rectangle(overlay, (0, 0), (width, 120), self.colors['background'], -1)
        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
        
        # í•˜ë‹¨ ì •ë³´ íŒ¨ë„
        cv2.rectangle(overlay, (0, height-80), (width, height), self.colors['background'], -1)
        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
        
        # ìì„¸ ìŠ¤ì¼ˆë ˆí†¤ ê·¸ë¦¬ê¸° (íšŒì „ëœ ì¢Œí‘œê³„ì—ì„œ)
        pose_results = debug_info.get('pose_results')
        if pose_results and pose_results.pose_landmarks:
            # ìŠ¤ì¼ˆë ˆí†¤ì„ ë” êµµê³  ëˆˆì— ë„ê²Œ
            self.pose_detector.mp_drawing.draw_landmarks(
                frame, 
                pose_results.pose_landmarks, 
                self.pose_detector.mp_pose.POSE_CONNECTIONS,
                landmark_drawing_spec=self.pose_detector.mp_drawing.DrawingSpec(
                    color=self.colors['skeleton'], thickness=4, circle_radius=6),
                connection_drawing_spec=self.pose_detector.mp_drawing.DrawingSpec(
                    color=self.colors['skeleton'], thickness=3)
            )
        
        # Ground Truth (ì™¼ìª½ ìƒë‹¨)
        if gt_gesture:
            gt_color = self.colors.get(gt_gesture, self.colors['text'])
            cv2.rectangle(frame, (10, 10), (300, 50), gt_color, 3)
            cv2.putText(frame, f'GROUND TRUTH: {gt_gesture.upper()}', (20, 35), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, gt_color, 2)
        else:
            # ì‹¤ì‹œê°„ ì¹´ë©”ë¼ ëª¨ë“œ
            cv2.rectangle(frame, (10, 10), (300, 50), (0, 255, 0), 3)
            cv2.putText(frame, 'LIVE CAMERA MODE', (20, 35), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
        
        # AI ì˜ˆì¸¡ (ì˜¤ë¥¸ìª½ ìƒë‹¨)
        if gesture and confidence > 0:
            pred_color = self.colors.get(gesture, self.colors['text'])
            cv2.rectangle(frame, (width-350, 10), (width-10, 50), pred_color, 3)
            cv2.putText(frame, f'AI PREDICTION: {gesture.upper()}', (width-340, 35), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, pred_color, 2)
            
            # ì‹ ë¢°ë„ ë°” (ì˜¤ë¥¸ìª½ ìƒë‹¨ ì•„ë˜)
            bar_width = int(300 * confidence)
            cv2.rectangle(frame, (width-350, 60), (width-50, 85), (64, 64, 64), -1)
            cv2.rectangle(frame, (width-350, 60), (width-350+bar_width, 85), pred_color, -1)
            cv2.putText(frame, f'Confidence: {confidence:.1%}', (width-340, 100), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, self.colors['text'], 2)
        
        # ì •í™•ì„± í‘œì‹œ (ì¤‘ì•™ ìƒë‹¨) - ë°ëª¨ ëª¨ë“œì—ì„œë§Œ
        if self.demo_mode and gesture and gt_gesture:
            is_correct = gesture == gt_gesture
            status_color = (0, 255, 0) if is_correct else (0, 0, 255)
            status_text = "CORRECT" if is_correct else "WRONG"
            
            cv2.rectangle(frame, (width//2-100, 10), (width//2+100, 50), status_color, 3)
            cv2.putText(frame, status_text, (width//2-80, 35), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, status_color, 2)
        
        # ì‹œìŠ¤í…œ ìƒíƒœ (í•˜ë‹¨ ì™¼ìª½)
        if self.demo_mode:
            total_frames = int(self.camera_cap.get(cv2.CAP_PROP_FRAME_COUNT)) if self.camera_cap else 1
            progress = (self.current_frame_idx / total_frames) * 100 if total_frames > 0 else 0
            status_text = f"Frame: {self.current_frame_idx}/{total_frames} ({progress:.1f}%)"
        else:
            status_text = f"Frame: {frame_count} | PDS Server Active"
        
        if self.redwing_connected:
            status_text += " | RedWing Connected"
        
        cv2.putText(frame, status_text, (10, height-50), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, self.colors['text'], 2)
        
        # ì œìŠ¤ì²˜ í™•ì‹ ë„ ì •ë³´ (í•˜ë‹¨ ì¤‘ì•™)
        conf_text = f"Confirmations: {self.gesture_confirmation['confirmation_count']}/{self.gesture_confirmation['required_confirmations']}"
        cv2.putText(frame, conf_text, (width//2-100, height-50), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, self.colors['text'], 2)
        
        # ëª¨ë¸ ì •ë³´ (í•˜ë‹¨ ì˜¤ë¥¸ìª½)
        cv2.putText(frame, "TCN Gesture Model", (width-200, height-50), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, self.colors['text'], 2)
        cv2.putText(frame, "Real-time Recognition", (width-200, height-25), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, self.colors['text'], 1)
        
        return frame

    def _process_improved_gesture_confirmation(self, gesture: str, confidence: float, debug_info: Dict):
        """ê°„ë‹¨í•œ ì œìŠ¤ì²˜ í™•ì‹ ë„ ì²˜ë¦¬"""
        current_time = time.time()
        
        # ì œìŠ¤ì²˜ í™•ì‹ ë„ ì¹´ìš´íŒ…
        if self.gesture_confirmation['current_gesture'] == gesture:
            self.gesture_confirmation['confirmation_count'] += 1
        else:
            # ìƒˆë¡œìš´ ì œìŠ¤ì²˜ - ì¹´ìš´íŠ¸ ë¦¬ì…‹
            self.gesture_confirmation['current_gesture'] = gesture
            self.gesture_confirmation['confirmation_count'] = 1
        
        # í•„ìš”í•œ í™•ì‹  íšŸìˆ˜ì— ë„ë‹¬í–ˆëŠ”ì§€ í™•ì¸
        if self.gesture_confirmation['confirmation_count'] >= self.gesture_confirmation['required_confirmations']:
            
            # ì¿¨ë‹¤ìš´ ì²´í¬
            if (self.last_gesture != gesture or 
                current_time - self.last_gesture_time > self.gesture_cooldown):
                
                self._send_improved_gesture_event(gesture, confidence, debug_info)
                self.last_gesture = gesture
                self.last_gesture_time = current_time
                
                # í™•ì‹ ë„ ì¹´ìš´íŠ¸ ë¦¬ì…‹
                self.gesture_confirmation['confirmation_count'] = 0
                
                self.logger.info(f"âœ… í™•ì¸ëœ ì œìŠ¤ì²˜ ì´ë²¤íŠ¸: {gesture} (ì‹ ë¢°ë„: {confidence:.2f})")

    def _unified_gui_loop(self):
        """ë‹¨ì¼ ìŠ¤ë ˆë“œì—ì„œ ëª¨ë“  GUI ê´€ë¦¬ (create_visual_demo.py ë°©ì‹)"""
        import time
        
        window_name = 'PDS Marshaling System'
        cv2.namedWindow(window_name, cv2.WINDOW_AUTOSIZE)
        cv2.moveWindow(window_name, 100, 100)
        
        # ì¹´ë©”ë¼ëŠ” í•„ìš”í•  ë•Œë§Œ ì´ˆê¸°í™”
        camera_cap = None
        frame_count = 0
        
        self.logger.info("ğŸ¯ í†µí•© GUI ë£¨í”„ ì‹œì‘ (create_visual_demo.py ë°©ì‹)")
        
        while self.is_running:
            try:
                if not self.marshaling_active:
                    # === ëŒ€ê¸° í™”ë©´ ëª¨ë“œ ===
                    if camera_cap:
                        # ì¹´ë©”ë¼ í•´ì œ
                        camera_cap.release()
                        camera_cap = None
                        self.logger.info("ğŸ“¹ ì¹´ë©”ë¼ í•´ì œ (ëŒ€ê¸° ëª¨ë“œ)")
                    
                    # ëŒ€ê¸° í™”ë©´ í‘œì‹œ
                    frame = np.zeros((480, 640, 3), dtype=np.uint8)
                    cv2.putText(frame, "PDS MARSHALING SYSTEM", (120, 150), 
                               cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)
                    cv2.putText(frame, "STATUS: STANDBY", (200, 220), 
                               cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 255), 2)
                    cv2.putText(frame, "Waiting for MARSHALING_START", (130, 300), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 1)
                    
                    cv2.imshow(window_name, frame)
                    time.sleep(0.5)  # ëŒ€ê¸° ëª¨ë“œì—ì„œëŠ” ëŠë¦¬ê²Œ ì—…ë°ì´íŠ¸
                    
                else:
                    # === ì¹´ë©”ë¼/ë°ëª¨ ì˜ìƒ í”¼ë“œ ëª¨ë“œ ===
                    if not camera_cap:
                        # ì¹´ë©”ë¼ ë˜ëŠ” ë°ëª¨ ì˜ìƒ ì´ˆê¸°í™”
                        camera_cap = self._initialize_camera()
                        if not camera_cap:
                            self.logger.error("âŒ ì¹´ë©”ë¼/ë°ëª¨ ì˜ìƒ ì´ˆê¸°í™” ì‹¤íŒ¨")
                            # ì—ëŸ¬ í™”ë©´ í‘œì‹œ
                            frame = np.zeros((480, 640, 3), dtype=np.uint8)
                            cv2.putText(frame, "CAMERA ERROR", (200, 240), 
                                       cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)
                            cv2.imshow(window_name, frame)
                            time.sleep(1.0)
                            continue
                        else:
                            self.logger.info("ğŸ“¹ ì¹´ë©”ë¼/ë°ëª¨ ì˜ìƒ ì´ˆê¸°í™” ì„±ê³µ")
                            frame_count = 0
                            self.camera_cap = camera_cap  # í´ë˜ìŠ¤ ë³€ìˆ˜ì—ë„ ì €ì¥
                    
                    # í”„ë ˆì„ ì½ê¸°
                    ret, frame = camera_cap.read()
                    if not ret or frame is None:
                        if self.demo_mode:
                            # ğŸ¬ ë°ëª¨ ì˜ìƒì´ ëë‚˜ë©´ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹œì‘
                            self.logger.info("ğŸ¬ ë°ëª¨ ì˜ìƒ ë - ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹œì‘")
                            camera_cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                            self.current_frame_idx = 0
                            continue
                        else:
                            self.logger.warning("âš ï¸ ì¹´ë©”ë¼ í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨")
                            camera_cap = None
                            continue
                    
                    frame_count += 1
                    if self.demo_mode:
                        self.current_frame_idx += 1
                    
                    # ğŸ¯ create_visual_demo.pyì™€ ë™ì¼í•œ ì œìŠ¤ì²˜ ì¸ì‹ ì²˜ë¦¬
                    try:
                        processed_frame, gesture, confidence, debug_info = self.pose_detector.process_frame(frame)
                        display_frame = processed_frame if processed_frame is not None else frame
                        
                        # ì œìŠ¤ì²˜ í™•ì‹ ë„ ê²€ì¦
                        if gesture and confidence > self.gesture_confirmation['confidence_threshold']:
                            self._process_improved_gesture_confirmation(gesture, confidence, debug_info)
                        
                        # ğŸ”„ GUI í‘œì‹œìš© íšŒì „ (90ë„ ì‹œê³„ë°©í–¥)
                        display_frame = self._auto_rotate_frame(display_frame)
                        
                        # ğŸ¨ íšŒì „ëœ í”„ë ˆì„ì— ë§ëŠ” ì˜¤ë²„ë ˆì´ ì ìš©
                        display_frame = self._draw_enhanced_gui_overlay_rotated(
                            display_frame, gesture, confidence, debug_info, frame_count)
                        
                        # í™”ë©´ì— ë§ê²Œ í¬ê¸° ì¡°ì • (ìµœëŒ€ 1280x720)
                        h, w = display_frame.shape[:2]
                        if w > 1280 or h > 720:
                            scale = min(1280/w, 720/h)
                            new_w, new_h = int(w * scale), int(h * scale)
                            display_frame = cv2.resize(display_frame, (new_w, new_h))
                        
                        cv2.imshow(window_name, display_frame)
                        
                        # ë°ëª¨ ëª¨ë“œì—ì„œ ì •í™•ë„ ë¡œê¹…
                        if self.demo_mode and gesture:
                            gt_gesture = self._get_current_ground_truth()
                            if gt_gesture:
                                if gesture == gt_gesture:
                                    self.logger.info(f"âœ… ì œìŠ¤ì²˜ ì¼ì¹˜: {gesture} (ì‹ ë¢°ë„: {confidence:.2f})")
                                else:
                                    self.logger.warning(f"ğŸš¨ ì œìŠ¤ì²˜ ë¶ˆì¼ì¹˜: ì˜ˆìƒ({gt_gesture}) vs ì¸ì‹({gesture}) (ì‹ ë¢°ë„: {confidence:.2f})")
                        
                    except Exception as e:
                        self.logger.error(f"ì œìŠ¤ì²˜ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                        # ì˜¤ë¥˜ ì‹œ ì›ë³¸ í”„ë ˆì„ í‘œì‹œ (íšŒì „ ë° í¬ê¸° ì¡°ì •)
                        cv2.putText(frame, "PROCESSING ERROR", (10, 60), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                        
                        # GUI í‘œì‹œìš© íšŒì „ ë° í¬ê¸° ì¡°ì •
                        error_frame = self._auto_rotate_frame(frame)
                        h, w = error_frame.shape[:2]
                        if w > 1280 or h > 720:
                            scale = min(1280/w, 720/h)
                            new_w, new_h = int(w * scale), int(h * scale)
                            error_frame = cv2.resize(error_frame, (new_w, new_h))
                        
                        cv2.imshow(window_name, error_frame)
                
                # í‚¤ ì…ë ¥ ì²˜ë¦¬
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    self.logger.info("ì‚¬ìš©ìê°€ 'q' í‚¤ë¡œ ì¢…ë£Œ ìš”ì²­")
                    self.stop_server()
                    break
                elif key == ord(' '):  # ìŠ¤í˜ì´ìŠ¤ë°”ë¡œ ë§ˆìƒ¬ë§ í† ê¸€
                    if self.marshaling_active:
                        self.logger.info("ì‚¬ìš©ìê°€ ìŠ¤í˜ì´ìŠ¤ë°”ë¡œ ë§ˆìƒ¬ë§ ì¤‘ì§€ ìš”ì²­")
                        self._stop_marshaling()
                    else:
                        self.logger.info("ì‚¬ìš©ìê°€ ìŠ¤í˜ì´ìŠ¤ë°”ë¡œ ë§ˆìƒ¬ë§ ì‹œì‘ ìš”ì²­")
                        self._start_marshaling()
                    
            except Exception as e:
                self.logger.error(f"GUI ë£¨í”„ ì˜¤ë¥˜: {e}")
                time.sleep(0.1)
        
        # ì •ë¦¬
        if camera_cap:
            camera_cap.release()
        cv2.destroyAllWindows()
        self.logger.info("í†µí•© GUI ë£¨í”„ ì¢…ë£Œ")

if __name__ == "__main__":
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(level=logging.INFO)
    
    # í¬íŠ¸ ì •ë³´ ì¶œë ¥
    from config import get_port_info
    get_port_info()
    
    # ë…ë¦½ì  ì„œë²„ ì‹œì‘
    server = IndependentPDSServer()
    
    try:
        server.start_server()
        
        print("\nğŸ¯ ë…ë¦½ì  PDS ì„œë²„ ì‹¤í–‰ ì¤‘...")
        print(f"ğŸ“¡ PDS ì„œë²„ í¬íŠ¸: {SERVER_CONFIG['port']}")
        print(f"ğŸ–¥ï¸  RedWing ì—°ê²°: {SERVER_CONFIG['redwing_host']}:{SERVER_CONFIG['redwing_port']}")
        print("ğŸš€ Main Serverì™€ ì™„ì „ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰")
        print("ğŸ¨ create_visual_demo.pyì™€ ë™ì¼í•œ ì •í™•í•œ ì²˜ë¦¬ ë°©ì‹ ì‚¬ìš©")
        print("ğŸ¯ ê°„ë‹¨í•œ ì œìŠ¤ì²˜ í™•ì‹ ë„: 30í”„ë ˆì„ ì—°ì† ê°ì§€ (ì•½ 1ì´ˆ, ì„ê³„ê°’: 0.9)")
        print("â° ì¿¨ë‹¤ìš´: 3.0ì´ˆ")
        print("\nğŸ® í‚¤ ì¡°ì‘:")
        print("  - ìŠ¤í˜ì´ìŠ¤ë°”: ë§ˆìƒ¬ë§ ì‹œì‘/ì¤‘ì§€")
        print("  - Q: ì„œë²„ ì¢…ë£Œ")
        
        # ğŸ¬ ë°ëª¨ ëª¨ë“œ ì •ë³´ ì¶œë ¥
        if DEMO_VIDEO_CONFIG['enabled']:
            print("\nğŸ¬ ë°ëª¨ ì˜ìƒ ëª¨ë“œ í™œì„±í™”")
            print("ğŸ“ concatenated_demo íŒŒì¼ ìë™ ê²€ìƒ‰")
            print("ğŸ” ë¬´í•œ ë°˜ë³µ ì¬ìƒ")
            print("ğŸ“Š ground truthì™€ ì‹¤ì‹œê°„ ë¹„êµ")
        else:
            print("\nğŸ“¹ ì‹¤ì‹œê°„ ì¹´ë©”ë¼ ëª¨ë“œ")
        
        print("\nğŸ’¡ ìŠ¤í˜ì´ìŠ¤ë°”ë¥¼ ëˆŒëŸ¬ ë§ˆìƒ¬ë§ì„ ì‹œì‘í•˜ì„¸ìš”!")
        print("Ctrl+Cë¡œ ì¢…ë£Œ")
        
        # ì„œë²„ ìœ ì§€
        while True:
            time.sleep(1)
            
    except KeyboardInterrupt:
        print("\nì„œë²„ ì¢…ë£Œ ì¤‘...")
        server.stop_server() 