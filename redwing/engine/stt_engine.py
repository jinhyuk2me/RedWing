import whisper
import io
import tempfile
import os
import torch
from typing import Optional

class WhisperSTTEngine:
    def __init__(self, model_name: str = "medium", language: str = "en", device: str = "auto"):
        """
        Whisper STT ì—”ì§„ ì´ˆê¸°í™” (í™œì£¼ë¡œ ìƒíƒœ & ì¡°ë¥˜ ìœ„í—˜ë„ ì „ìš©)
        
        Args:
            model_name: whisper ëª¨ë¸ í¬ê¸° (tiny, base, small, medium, large, large-v2, large-v3)
            language: ì¸ì‹í•  ì–¸ì–´ ì½”ë“œ (ko, en ë“±)
            device: ì‹¤í–‰ ì¥ì¹˜ ("auto", "cuda", "cpu")
        """
        self.model_name = model_name
        self.language = language
        self.device = self._determine_device(device)
        self.model = None
        self.aviation_prompt = ""
        
        self._setup_gpu_memory()
        self._load_model()
    
    def _determine_device(self, device: str) -> str:
        """
        ìµœì ì˜ ì‹¤í–‰ ì¥ì¹˜ ê²°ì •
        """
        if device == "auto":
            if torch.cuda.is_available():
                # GPU ë©”ëª¨ë¦¬ í™•ì¸
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3  # GB
                print(f"[WhisperSTT] GPU ë©”ëª¨ë¦¬: {gpu_memory:.1f}GB")
                
                # Large ëª¨ë¸ì„ ìœ„í•´ ì„ê³„ê°’ì„ 5.5GBë¡œ ì¡°ì • (100% ì‚¬ìš©ìœ¼ë¡œ ì—¬ìœ  í™•ë³´)
                if gpu_memory >= 5.5:
                    return "cuda"
                else:
                    print(f"[WhisperSTT] GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ({gpu_memory:.1f}GB < 5.5GB), CPU ì‚¬ìš©")
                    return "cpu"
            else:
                return "cpu"
        return device
    
    def _setup_gpu_memory(self):
        """
        GPU ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì •
        """
        if self.device == "cuda" and torch.cuda.is_available():
            # GPU ë©”ëª¨ë¦¬ ìºì‹œ ì •ë¦¬
            torch.cuda.empty_cache()
            
            # ë©”ëª¨ë¦¬ í• ë‹¹ ì „ëµ ì„¤ì • - ë¶„í•  í¬ê¸° ì œí•œìœ¼ë¡œ Large ëª¨ë¸ ì§€ì›
            os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True,max_split_size_mb:256'
            
            # ë©”ëª¨ë¦¬ ë¶„í•  ë°©ì§€ - Large ëª¨ë¸ì„ ìœ„í•´ 98%ë¡œ ì„¤ì • (ì•½ê°„ì˜ ì—¬ìœ )
            torch.cuda.set_per_process_memory_fraction(0.98)  # GPU ë©”ëª¨ë¦¬ì˜ 98% ì‚¬ìš©
            
            print(f"[WhisperSTT] GPU ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì • ì™„ë£Œ (98% ì‚¬ìš©, ë¶„í•  ì œí•œ)")
    
    def _load_model(self):
        """
        Whisper ëª¨ë¸ ë¡œë”© - GPU ë©”ëª¨ë¦¬ ìµœì í™” ë²„ì „
        """
        try:
            print(f"[WhisperSTT] {self.model_name} ëª¨ë¸ ë¡œë”© ì¤‘... (ì¥ì¹˜: {self.device})")
            
            if self.device == "cuda":
                print(f"[WhisperSTT] GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì¤‘...")
                torch.cuda.empty_cache()
                
                # í˜„ì¬ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
                allocated = torch.cuda.memory_allocated() / 1024**3
                cached = torch.cuda.memory_reserved() / 1024**3
                print(f"[WhisperSTT] GPU ë©”ëª¨ë¦¬ - í• ë‹¹ë¨: {allocated:.2f}GB, ìºì‹œë¨: {cached:.2f}GB")
            
            print(f"[WhisperSTT] ì£¼ì˜: {self.model_name} ëª¨ë¸ì€ ì•½ 3GB í¬ê¸°ë¡œ ì²˜ìŒ ë‹¤ìš´ë¡œë“œ ì‹œ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            # ëª¨ë¸ ë¡œë”© ì‹œ ì¥ì¹˜ ì§€ì •
            self.model = whisper.load_model(self.model_name, device=self.device)
            print(f"[WhisperSTT] {self.model_name} ëª¨ë¸ ë¡œë”© ì™„ë£Œ - í™œì£¼ë¡œ/ì¡°ë¥˜ ìš”ì²­ ìµœì í™” ({self.device})")
            
        except RuntimeError as e:
            if "CUDA out of memory" in str(e):
                print(f"[WhisperSTT] GPU ë©”ëª¨ë¦¬ ë¶€ì¡±: {e}")
                print(f"[WhisperSTT] medium ëª¨ë¸ë¡œ í´ë°±í•©ë‹ˆë‹¤...")
                try:
                    torch.cuda.empty_cache()  # ë©”ëª¨ë¦¬ ì •ë¦¬
                    self.model = whisper.load_model("medium", device=self.device)
                    self.model_name = "medium"
                    print(f"[WhisperSTT] medium ëª¨ë¸ ë¡œë”© ì™„ë£Œ ({self.device})")
                except RuntimeError as e2:
                    if "CUDA out of memory" in str(e2):
                        print(f"[WhisperSTT] medium ëª¨ë¸ë„ ì‹¤íŒ¨, CPUë¡œ ì „í™˜: {e2}")
                        try:
                            self.device = "cpu"
                            self.model = whisper.load_model("medium", device="cpu")
                            self.model_name = "medium"
                            print(f"[WhisperSTT] medium ëª¨ë¸ ë¡œë”© ì™„ë£Œ (CPU)")
                        except Exception as e3:
                            print(f"[WhisperSTT] CPUì—ì„œë„ ì‹¤íŒ¨, base ëª¨ë¸ë¡œ í´ë°±: {e3}")
                            try:
                                self.model = whisper.load_model("base", device="cpu")
                                self.model_name = "base"
                                self.device = "cpu"
                                print(f"[WhisperSTT] base ëª¨ë¸ ë¡œë”© ì™„ë£Œ (CPU)")
                            except Exception as e4:
                                print(f"[WhisperSTT] ëª¨ë“  ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e4}")
                                self.model = None
                    else:
                        raise e2
            else:
                raise e
        except Exception as e:
            print(f"[WhisperSTT] ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            print(f"[WhisperSTT] base ëª¨ë¸ë¡œ í´ë°±í•©ë‹ˆë‹¤...")
            try:
                self.model = whisper.load_model("base", device="cpu")
                self.model_name = "base"
                self.device = "cpu"
                print(f"[WhisperSTT] base ëª¨ë¸ ë¡œë”© ì™„ë£Œ (CPU)")
            except Exception as e2:
                print(f"[WhisperSTT] ëª¨ë“  ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e2}")
                self.model = None

    def transcribe(self, audio_bytes: bytes, session_id: str = "") -> str:
        """
        ìŒì„± ë°ì´í„°(WAV ë°”ì´íŠ¸) â†’ í…ìŠ¤íŠ¸ ë°˜í™˜ (í™œì£¼ë¡œ/ì¡°ë¥˜ ìš”ì²­ ìµœì í™”)
        """
        if self.model is None:
            print("[WhisperSTT] ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return ""
        
        try:
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬ (GPU ì‚¬ìš© ì‹œ)
            if self.device == "cuda":
                torch.cuda.empty_cache()
            
            # ì„ì‹œ íŒŒì¼ì— ì˜¤ë””ì˜¤ ë°ì´í„° ì €ì¥
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_file:
                temp_file.write(audio_bytes)
                temp_file_path = temp_file.name
            
            print(f"[WhisperSTT] ìŒì„± ì¸ì‹ ì‹œì‘... (ëª¨ë¸: {self.model_name}, ì¥ì¹˜: {self.device}, ì„¸ì…˜: {session_id})")
            
            # ëª¨ë¸ í¬ê¸°ì— ë”°ë¥¸ ìµœì í™” ì„¤ì • (í™˜ê° ë°©ì§€ ê°•í™”)
            if "large" in self.model_name:
                # large ëª¨ë¸ìš© ê³ í’ˆì§ˆ ì„¤ì •
                transcribe_options = {
                    "language": "en",  # ì˜ì–´ë¡œ ëª…ì‹œì  ê³ ì •
                    "task": "transcribe",  # ë²ˆì—­ ë°©ì§€, ì „ì‚¬ë§Œ ìˆ˜í–‰
                    "fp16": self.device == "cuda",  # GPUì—ì„œë§Œ fp16 ì‚¬ìš©
                    "verbose": False,
                    "temperature": 0.0,  # ì™„ì „ ê²°ì •ì  ì¶œë ¥
                    "beam_size": 5,
                    "best_of": 5,
                    "no_speech_threshold": 0.95,  # ë” ë†’ì„ (0.9 â†’ 0.95)
                    "logprob_threshold": -0.3,   # ë” ì—„ê²©í•¨ (-0.5 â†’ -0.3)
                    "compression_ratio_threshold": 1.8,  # ë” ì—„ê²©í•¨ (2.0 â†’ 1.8)
                    "condition_on_previous_text": False,  # ì´ì „ í…ìŠ¤íŠ¸ ì˜í–¥ ì°¨ë‹¨
                    "initial_prompt": "English aviation communication only. No foreign languages.",  # ì˜ì–´ ì „ìš© íŒíŠ¸
                    "suppress_tokens": [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362]  # í™˜ê° ë°©ì§€ í† í°ë“¤
                }
            else:
                # medium/small ëª¨ë¸ìš© ê¸°ë³¸ ì„¤ì •
                transcribe_options = {
                    "language": "en",  # ì˜ì–´ë¡œ ëª…ì‹œì  ê³ ì •
                    "task": "transcribe",  # ë²ˆì—­ ë°©ì§€, ì „ì‚¬ë§Œ ìˆ˜í–‰
                    "fp16": False,  # ì•ˆì •ì„±ì„ ìœ„í•´ fp16 ë¹„í™œì„±í™”
                    "verbose": False,
                    "temperature": 0.0,  # ì™„ì „ ê²°ì •ì  ì¶œë ¥
                    "no_speech_threshold": 0.95,  # ë” ë†’ì„ (0.9 â†’ 0.95)
                    "logprob_threshold": -0.3,   # ë” ì—„ê²©í•¨ (-0.5 â†’ -0.3)
                    "compression_ratio_threshold": 1.8,  # ë” ì—„ê²©í•¨ (2.0 â†’ 1.8)
                    "condition_on_previous_text": False,  # ì´ì „ í…ìŠ¤íŠ¸ ì˜í–¥ ì°¨ë‹¨
                    "initial_prompt": "English aviation communication only. No foreign languages.",  # ì˜ì–´ ì „ìš© íŒíŠ¸
                    "suppress_tokens": [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362]  # í™˜ê° ë°©ì§€ í† í°ë“¤
                }
            
            # Whisperë¡œ ìŒì„± ì¸ì‹
            result = self.model.transcribe(temp_file_path, **transcribe_options)
            
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            os.unlink(temp_file_path)
            
            transcribed_text = result["text"].strip()
            
            # í™˜ê° ê²°ê³¼ ê²€ì¦ ë° í•„í„°ë§
            transcribed_text = self._validate_transcription_result(transcribed_text)
            
            # 2ê°€ì§€ ìš”ì²­ì— íŠ¹í™”ëœ í›„ì²˜ë¦¬
            transcribed_text = self._postprocess_specialized_terms(transcribed_text)
            
            print(f"[WhisperSTT] ì¸ì‹ ê²°ê³¼: '{transcribed_text}'")
            
            return transcribed_text
            
        except Exception as e:
            print(f"[WhisperSTT] ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {e}")
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if 'temp_file_path' in locals() and os.path.exists(temp_file_path):
                os.unlink(temp_file_path)
            return ""
    
    def _postprocess_specialized_terms(self, text: str) -> str:
        """
        í™œì£¼ë¡œ ìƒíƒœ & ì¡°ë¥˜ ìœ„í—˜ë„ ìš”ì²­ì— íŠ¹í™”ëœ í›„ì²˜ë¦¬
        """
        if not text:
            return text
        
        # ëŒ€ì†Œë¬¸ì ì •ê·œí™”
        processed_text = text.strip()
        
        # ì½œì‚¬ì¸ ì •ê·œí™” (FALCON ìš°ì„ )
        import re
        
        # FALCON ì½œì‚¬ì¸ íŒ¨í„´ ê°•í™”
        falcon_patterns = [
            (r'\b(?:falcon|falkon|faulcon|folcon)\s*(\d{1,4}[a-z]?)\b', r'FALCON \1'),
            (r'\b(?:f\s*a\s*l\s*c\s*o\s*n)\s*(\d{1,4}[a-z]?)\b', r'FALCON \1'),
        ]
        
        for pattern, replacement in falcon_patterns:
            processed_text = re.sub(pattern, replacement, processed_text, flags=re.IGNORECASE)
        
        # í™œì£¼ë¡œ ë²ˆí˜¸ ì •ê·œí™” (ì£¼ìš” í™œì£¼ë¡œë§Œ)
        runway_patterns = [
            (r'\brunway\s*(\d{1,2})\s*([lrc]?)\b', r'runway \1\2'),
            (r'\brwy\s*(\d{1,2})\s*([lrc]?)\b', r'runway \1\2'),
            (r'\b(\d{1,2})\s*([lrc]?)\s*runway\b', r'runway \1\2'),
            # íŠ¹ì • í™œì£¼ë¡œ ë²ˆí˜¸ ê°•í™”
            (r'\b(?:25|twenty.?five)\s*([lrc]?)\b', r'25\1'),
            (r'\b(?:07|seven|oh.?seven)\s*([lrc]?)\b', r'07\1'),
        ]
        
        for pattern, replacement in runway_patterns:
            processed_text = re.sub(pattern, replacement, processed_text, flags=re.IGNORECASE)
        
        # í•µì‹¬ í‚¤ì›Œë“œ ì •ê·œí™” (2ê°€ì§€ ìš”ì²­ì— íŠ¹í™”)
        keyword_corrections = {
            # ì¡°ë¥˜ ê´€ë ¨
            r'\b(?:bird|birds|burd|berds|bert)\b': 'bird',
            r'\b(?:wildlife|wild.?life|wildlive)\b': 'wildlife',
            r'\b(?:risk|risks|risc)\b': 'risk',
            r'\b(?:activity|activities|activety)\b': 'activity',
            r'\b(?:assessment|assesment|asessment)\b': 'assessment',
            
            # í™œì£¼ë¡œ ê´€ë ¨
            r'\b(?:runway|run.?way|runaway)\b': 'runway',
            r'\b(?:status|state|condition)\b': 'status',
            r'\b(?:check|chek|cheque)\b': 'check',
            r'\b(?:clear|cleared|cler)\b': 'clear',
            r'\b(?:operational|operation|operatinal)\b': 'operational',
            
            # ê³µí†µ
            r'\b(?:request|reqest|reques)\b': 'request',
        }
        
        for pattern, replacement in keyword_corrections.items():
            processed_text = re.sub(pattern, replacement, processed_text, flags=re.IGNORECASE)
        
        # ìˆ«ì ì •ê·œí™”
        number_corrections = {
            r'\b(?:one|won)\b': '1',
            r'\b(?:two|too|to)\b': '2', 
            r'\b(?:three|tree)\b': '3',
            r'\b(?:four|for|fore)\b': '4',
            r'\b(?:five|fiv)\b': '5',
            r'\b(?:six|siks)\b': '6',
            r'\b(?:seven|sevn)\b': '7',
            r'\b(?:eight|ate)\b': '8',
            r'\b(?:nine|nien)\b': '9',
            r'\b(?:zero|oh)\b': '0',
        }
        
        for pattern, replacement in number_corrections.items():
            processed_text = re.sub(pattern, replacement, processed_text, flags=re.IGNORECASE)
        
        # ìµœì¢… ì •ë¦¬
        processed_text = re.sub(r'\s+', ' ', processed_text).strip()
        
        return processed_text

    def transcribe_with_confidence(self, audio_bytes: bytes, session_id: str = "") -> tuple[str, float]:
        """
        ìŒì„± ì¸ì‹ê³¼ í•¨ê»˜ ì‹ ë¢°ë„ ì ìˆ˜ ë°˜í™˜ (í™œì£¼ë¡œ/ì¡°ë¥˜ ìš”ì²­ ìµœì í™”)
        """
        if self.model is None:
            return "", 0.0
        
        try:
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            if self.device == "cuda":
                torch.cuda.empty_cache()
            
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_file:
                temp_file.write(audio_bytes)
                temp_file_path = temp_file.name
            
            print(f"[WhisperSTT] ì‹ ë¢°ë„ í¬í•¨ ìŒì„± ì¸ì‹... (ëª¨ë¸: {self.model_name}, ì¥ì¹˜: {self.device})")
            
            # ëª¨ë¸ í¬ê¸°ì— ë”°ë¥¸ ìµœì í™” ì„¤ì • (í™˜ê° ë°©ì§€ ê°•í™”)
            if "large" in self.model_name:
                # large ëª¨ë¸ìš© ê³ í’ˆì§ˆ ì„¤ì •
                transcribe_options = {
                    "language": "en",  # ì˜ì–´ë¡œ ëª…ì‹œì  ê³ ì •
                    "task": "transcribe",  # ë²ˆì—­ ë°©ì§€, ì „ì‚¬ë§Œ ìˆ˜í–‰
                    "fp16": self.device == "cuda",  # GPUì—ì„œë§Œ fp16 ì‚¬ìš©
                    "verbose": False,
                    "temperature": 0.0,  # ì™„ì „ ê²°ì •ì  ì¶œë ¥
                    "beam_size": 5,
                    "best_of": 5,
                    "no_speech_threshold": 0.95,  # ë” ë†’ì„ (0.9 â†’ 0.95)
                    "logprob_threshold": -0.3,   # ë” ì—„ê²©í•¨ (-0.5 â†’ -0.3)
                    "compression_ratio_threshold": 1.8,  # ë” ì—„ê²©í•¨ (2.0 â†’ 1.8)
                    "condition_on_previous_text": False,  # ì´ì „ í…ìŠ¤íŠ¸ ì˜í–¥ ì°¨ë‹¨
                    "initial_prompt": "English aviation communication only. No foreign languages.",  # ì˜ì–´ ì „ìš© íŒíŠ¸
                    "suppress_tokens": [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362]  # í™˜ê° ë°©ì§€ í† í°ë“¤
                }
            else:
                # medium/small ëª¨ë¸ìš© ê¸°ë³¸ ì„¤ì •
                transcribe_options = {
                    "language": "en",  # ì˜ì–´ë¡œ ëª…ì‹œì  ê³ ì •
                    "task": "transcribe",  # ë²ˆì—­ ë°©ì§€, ì „ì‚¬ë§Œ ìˆ˜í–‰
                    "fp16": False,  # ì•ˆì •ì„±ì„ ìœ„í•´ fp16 ë¹„í™œì„±í™”
                    "verbose": False,
                    "temperature": 0.0,  # ì™„ì „ ê²°ì •ì  ì¶œë ¥
                    "no_speech_threshold": 0.95,  # ë” ë†’ì„ (0.9 â†’ 0.95)
                    "logprob_threshold": -0.3,   # ë” ì—„ê²©í•¨ (-0.5 â†’ -0.3)
                    "compression_ratio_threshold": 1.8,  # ë” ì—„ê²©í•¨ (2.0 â†’ 1.8)
                    "condition_on_previous_text": False,  # ì´ì „ í…ìŠ¤íŠ¸ ì˜í–¥ ì°¨ë‹¨
                    "initial_prompt": "English aviation communication only. No foreign languages.",  # ì˜ì–´ ì „ìš© íŒíŠ¸
                    "suppress_tokens": [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362]  # í™˜ê° ë°©ì§€ í† í°ë“¤
                }
            
            result = self.model.transcribe(temp_file_path, **transcribe_options)
            
            os.unlink(temp_file_path)
            
            text = result["text"].strip()
            
            # í™˜ê° ê²°ê³¼ ê²€ì¦ ë° í•„í„°ë§
            text = self._validate_transcription_result(text)
            
            # 2ê°€ì§€ ìš”ì²­ì— íŠ¹í™”ëœ í›„ì²˜ë¦¬
            text = self._postprocess_specialized_terms(text)
            
            # ì‹ ë¢°ë„ ê³„ì‚° (segments ê¸°ë°˜)
            avg_confidence = self._calculate_confidence_score(result)
            
            print(f"[WhisperSTT] ì¸ì‹ ê²°ê³¼: '{text}' (ì‹ ë¢°ë„: {avg_confidence:.3f})")
            
            return text, avg_confidence
            
        except Exception as e:
            print(f"[WhisperSTT] ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {e}")
            if 'temp_file_path' in locals() and os.path.exists(temp_file_path):
                os.unlink(temp_file_path)
            return "", 0.0
    
    def _calculate_confidence_score(self, result: dict) -> float:
        """
        Whisper ê²°ê³¼ì—ì„œ ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚° (ê°œì„ ëœ ì•Œê³ ë¦¬ì¦˜)
        """
        try:
            # segmentsê°€ ìˆëŠ” ê²½ìš° ì‚¬ìš©
            if "segments" in result and result["segments"]:
                confidences = []
                total_duration = 0
                
                for segment in result["segments"]:
                    segment_duration = segment.get("end", 0) - segment.get("start", 0)
                    total_duration += segment_duration
                    
                    if "avg_logprob" in segment:
                        # log probabilityë¥¼ 0-1 ë²”ìœ„ë¡œ ë³€í™˜ (ê°œì„ ëœ ê³µì‹)
                        logprob = segment["avg_logprob"]
                        # -2.0 ~ 0.0 ë²”ìœ„ë¥¼ 0.0 ~ 1.0ìœ¼ë¡œ ë§¤í•‘
                        confidence = max(0.0, min(1.0, (logprob + 2.0) / 2.0))
                        
                        # ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´ë¡œ ê°€ì¤‘í‰ê· 
                        confidences.append((confidence, segment_duration))
                    
                    # no_speech_prob ë°˜ì˜
                    if "no_speech_prob" in segment:
                        speech_confidence = 1.0 - segment["no_speech_prob"]
                        confidences.append((speech_confidence, segment_duration))
                
                if confidences and total_duration > 0:
                    # ê°€ì¤‘í‰ê·  ê³„ì‚°
                    weighted_sum = sum(conf * duration for conf, duration in confidences)
                    total_weight = sum(duration for _, duration in confidences)
                    return weighted_sum / total_weight if total_weight > 0 else 0.5
            
            # segmentsê°€ ì—†ëŠ” ê²½ìš° ì „ì²´ ê²°ê³¼ì—ì„œ ì¶”ì •
            if "text" in result and result["text"].strip():
                # í…ìŠ¤íŠ¸ ê¸¸ì´ ê¸°ë°˜ ê¸°ë³¸ ì‹ ë¢°ë„
                text_length = len(result["text"].strip())
                if text_length > 10:
                    return 0.7  # ê¸´ í…ìŠ¤íŠ¸ëŠ” ë†’ì€ ì‹ ë¢°ë„
                elif text_length > 5:
                    return 0.6  # ì¤‘ê°„ ê¸¸ì´
                else:
                    return 0.5  # ì§§ì€ í…ìŠ¤íŠ¸
            
            return 0.5  # ê¸°ë³¸ê°’
                
        except Exception as e:
            print(f"[WhisperSTT] ì‹ ë¢°ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return 0.5

    def is_model_loaded(self) -> bool:
        """
        ëª¨ë¸ ë¡œë”© ìƒíƒœ í™•ì¸
        """
        return self.model is not None
    
    def get_model_info(self) -> dict:
        """
        í˜„ì¬ ëª¨ë¸ ì •ë³´ ë°˜í™˜
        """
        gpu_info = ""
        if torch.cuda.is_available() and self.device == "cuda":
            allocated = torch.cuda.memory_allocated() / 1024**3
            cached = torch.cuda.memory_reserved() / 1024**3
            gpu_info = f" (GPU ë©”ëª¨ë¦¬: {allocated:.2f}GB í• ë‹¹, {cached:.2f}GB ìºì‹œ)"
        
        return {
            "model_name": self.model_name,
            "language": self.language,
            "device": self.device,
            "is_loaded": self.is_model_loaded(),
            "model_size": "~3GB" if "large" in self.model_name else "~1GB" if "medium" in self.model_name else "~150MB",
            "gpu_memory": gpu_info
        }
    
    def clear_gpu_memory(self):
        """
        GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        """
        if self.device == "cuda" and torch.cuda.is_available():
            torch.cuda.empty_cache()
            print("[WhisperSTT] GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")
    
    def reload_model(self, model_name: Optional[str] = None, device: Optional[str] = None):
        """
        ëª¨ë¸ ì¬ë¡œë”©
        """
        if model_name:
            self.model_name = model_name
        if device:
            self.device = self._determine_device(device)
        
        # ê¸°ì¡´ ëª¨ë¸ ì •ë¦¬
        if self.model is not None:
            del self.model
            self.model = None
        
        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        self.clear_gpu_memory()
        
        # ìƒˆ ëª¨ë¸ ë¡œë”©
        self._setup_gpu_memory()
        self._load_model()

    def _validate_transcription_result(self, text: str) -> str:
        """
        í™˜ê° ê²°ê³¼ ê²€ì¦ ë° í•„í„°ë§ - ì˜ì–´ ì „ìš© ê°•í™”
        """
        if not text:
            return text
        
        import re
        
        # 1. ì˜ë¯¸ì—†ëŠ” ë°˜ë³µ ë¬¸ì ì œê±° (~~, ..., ---, ë“±)
        if re.match(r'^[~\-_.!@#$%^&*()+=\[\]{}|\\:";\'<>?,./\s]*$', text):
            print(f"[WhisperSTT] í™˜ê° ê°ì§€: ì˜ë¯¸ì—†ëŠ” ë°˜ë³µ ë¬¸ì '{text}'")
            return ""
        
        # 2. ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸ (1-2ê¸€ì)
        if len(text.strip()) <= 2:
            print(f"[WhisperSTT] í™˜ê° ê°ì§€: ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸ '{text}'")
            return ""
        
        # 3. ë¹„ì˜ì–´ ë¬¸ì ì™„ì „ ì œê±° (ìˆ˜ì •ëœ íŒ¨í„´)
        # ê° ì–¸ì–´ë³„ë¡œ ê°œë³„ íŒ¨í„´ ì‚¬ìš©í•˜ì—¬ ë²”ìœ„ ì˜¤ë¥˜ ë°©ì§€
        korean_pattern = r'[ê°€-í£]'
        chinese_pattern = r'[ä¸€-é¾¯ã€-ä¶µè±ˆ-é¾]'
        japanese_hiragana_pattern = r'[ã²ã‚‰ãŒãª]'
        japanese_katakana_pattern = r'[ã‚«ã‚¿ã‚«ãƒŠã‚¡-ãƒ¾]'
        fullwidth_pattern = r'[ï¼¡ï¼¢ï¼£ï¼¤ï¼¥ï¼¦ï¼§ï¼¨ï¼©ï¼ªï¼«ï¼¬ï¼­ï¼®ï¼¯ï¼°ï¼±ï¼²ï¼³ï¼´ï¼µï¼¶ï¼·ï¼¸ï¼¹ï¼ºï½ï½‚ï½ƒï½„ï½…ï½†ï½‡ï½ˆï½‰ï½Šï½‹ï½Œï½ï½ï½ï½ï½‘ï½’ï½“ï½”ï½•ï½–ï½—ï½˜ï½™ï½š]'
        special_brackets_pattern = r'[ã€Šã€‹ã€Œã€ã€ã€ã€ã€‘ã€ˆã€‰ã€”ã€•ï¼»ï¼½ï½›ï½ï¼ˆï¼‰ã€–ã€—ã€˜ã€™ã€šã€›ï¼œï¼â€¹â€ºÂ«Â»""''â€šâ€â€›â€Ÿ]'
        greek_pattern = r'[Î±Î²Î³Î´ÎµÎ¶Î·Î¸Î¹ÎºÎ»Î¼Î½Î¾Î¿Ï€ÏÏƒÏ„Ï…Ï†Ï‡ÏˆÏ‰Î‘Î’Î“Î”Î•Î–Î—Î˜Î™ÎšÎ›ÎœÎÎÎŸÎ Î¡Î£Î¤Î¥Î¦Î§Î¨Î©]'
        cyrillic_pattern = r'[Ğ°Ğ±Ğ²Ğ³Ğ´ĞµÑ‘Ğ¶Ğ·Ğ¸Ğ¹ĞºĞ»Ğ¼Ğ½Ğ¾Ğ¿Ñ€ÑÑ‚ÑƒÑ„Ñ…Ñ†Ñ‡ÑˆÑ‰ÑŠÑ‹ÑŒÑÑÑĞĞ‘Ğ’Ğ“Ğ”Ğ•ĞĞ–Ğ—Ğ˜Ğ™ĞšĞ›ĞœĞĞĞŸĞ Ğ¡Ğ¢Ğ£Ğ¤Ğ¥Ğ¦Ğ§Ğ¨Ğ©ĞªĞ«Ğ¬Ğ­Ğ®Ğ¯]'
        
        # ê° íŒ¨í„´ë³„ë¡œ ê°œë³„ ê²€ì‚¬
        non_english_patterns = [
            korean_pattern, chinese_pattern, japanese_hiragana_pattern, 
            japanese_katakana_pattern, fullwidth_pattern, special_brackets_pattern,
            greek_pattern, cyrillic_pattern
        ]
        
        for pattern in non_english_patterns:
            if re.search(pattern, text):
                print(f"[WhisperSTT] í™˜ê° ê°ì§€: ë¹„ì˜ì–´ ë¬¸ì í¬í•¨ '{text}'")
                return ""
        
        # 4. íŠ¹ìˆ˜ ìœ ë‹ˆì½”ë“œ ë¬¸ì ì œê±° (í™˜ê°ì—ì„œ ìì£¼ ë‚˜íƒ€ë‚˜ëŠ” ë¬¸ìë“¤)
        # ğŸ†• í•­ê³µ í†µì‹ ì—ì„œ í—ˆìš©ë˜ëŠ” ë¹„ASCII ë¬¸ì (ìœ ëŸ½ì–´ ì•…ì„¼íŠ¸ ë“±) ì˜ˆì™¸ ì²˜ë¦¬
        allowed_non_ascii = r'[Ã Ã¡Ã¢Ã£Ã¤Ã¥Ã¦Ã§Ã¨Ã©ÃªÃ«Ã¬Ã­Ã®Ã¯Ã°Ã±Ã²Ã³Ã´ÃµÃ¶Ã¸Ã¹ÃºÃ»Ã¼Ã½Ã¾Ã¿Ã€ÃÃ‚ÃƒÃ„Ã…Ã†Ã‡ÃˆÃ‰ÃŠÃ‹ÃŒÃÃÃÃÃ‘Ã’Ã“Ã”Ã•Ã–Ã˜Ã™ÃšÃ›ÃœÃÃÅ¸]'  # ìœ ëŸ½ì–´ ì•…ì„¼íŠ¸
        
        # í—ˆìš©ëœ ë¹„ASCII ë¬¸ìë¥¼ ì„ì‹œë¡œ ì œê±°í•˜ê³  ê²€ì‚¬
        temp_text = re.sub(allowed_non_ascii, 'X', text)  # í—ˆìš©ëœ ë¬¸ìë¥¼ Xë¡œ ì¹˜í™˜
        unicode_hallucination_pattern = r'[^\x00-\x7F]'  # ASCII ë²”ìœ„ ì™¸ ëª¨ë“  ë¬¸ì
        
        if re.search(unicode_hallucination_pattern, temp_text):
            print(f"[WhisperSTT] í™˜ê° ê°ì§€: ë¹„ASCII ë¬¸ì í¬í•¨ '{text}'")
            return ""
        
        # 5. ìˆ«ìë§Œ ìˆëŠ” ê²½ìš°
        if re.match(r'^[\d\s]*$', text):
            print(f"[WhisperSTT] í™˜ê° ê°ì§€: ìˆ«ìë§Œ í¬í•¨ '{text}'")
            return ""
        
        # 6. íŠ¹ìˆ˜ë¬¸ìë§Œ ìˆëŠ” ê²½ìš°
        if re.match(r'^[^\w\s]*$', text):
            print(f"[WhisperSTT] í™˜ê° ê°ì§€: íŠ¹ìˆ˜ë¬¸ìë§Œ í¬í•¨ '{text}'")
            return ""
        
        # 7. ì˜ë¯¸ì—†ëŠ” ë‹¨ì–´ ë°˜ë³µ
        words = text.split()
        if len(words) > 1:
            # ê°™ì€ ë‹¨ì–´ê°€ 3ë²ˆ ì´ìƒ ë°˜ë³µ
            for word in set(words):
                if words.count(word) >= 3:
                    print(f"[WhisperSTT] í™˜ê° ê°ì§€: ë‹¨ì–´ ë°˜ë³µ '{text}'")
                    return ""
        
        # 8. ì•Œë ¤ì§„ í™˜ê° íŒ¨í„´ë“¤ (ì •ê·œì‹)
        hallucination_patterns = [
            r'^[a-z]{1,2}$',  # ë‹¨ì¼ ì•ŒíŒŒë²³
            r'^\s*$',         # ê³µë°±ë§Œ
            r'^[.]{3,}$',     # ì ë§Œ ë°˜ë³µ
            r'^[-]{3,}$',     # ëŒ€ì‹œë§Œ ë°˜ë³µ
            r'^[~]{2,}$',     # í‹¸ë“œ ë°˜ë³µ
            r'^[*]{2,}$',     # ë³„í‘œ ë°˜ë³µ
            r'^[#]{2,}$',     # í•´ì‹œ ë°˜ë³µ
        ]
        
        for pattern in hallucination_patterns:
            if re.match(pattern, text):
                print(f"[WhisperSTT] í™˜ê° ê°ì§€: íŒ¨í„´ ë§¤ì¹˜ '{text}'")
                return ""
        
        # 9. Whisper íŠ¹ì • í™˜ê° ë¬¸êµ¬ë“¤ (ëŒ€ì†Œë¬¸ì ë¬´ê´€)
        whisper_hallucinations = [
            "no foreign languages",
            "no foreign language",
            "foreign languages",
            "foreign language",
            "thank you for watching",
            "thanks for watching", 
            "please subscribe",
            "like and subscribe",
            "don't forget to subscribe",
            "see you next time",
            "see you later",
            "goodbye",
            "bye bye",
            "music",
            "applause",
            "laughter",
            "silence",
            "inaudible",
            "unintelligible",
            "unclear",
            "background noise",
            "static",
            "beep",
            "beeping",
            "uh uh uh",
            "um um um",
            "ah ah ah",
            "oh oh oh",
            "hmm hmm",
            "mm mm",
            "you know",
            "i mean",
            "like you know",
            "so yeah",
            "okay okay",
            "alright alright",
            "test test",
            "testing testing",
            "hello hello",
            "can you hear me",
            "is this working",
            "one two three",
            "check check",
            "mic check"
        ]
        
        text_lower = text.lower().strip()
        for hallucination in whisper_hallucinations:
            if text_lower == hallucination or text_lower.startswith(hallucination + ".") or text_lower.startswith(hallucination + "?"):
                print(f"[WhisperSTT] í™˜ê° ê°ì§€: Whisper íŠ¹ì • í™˜ê° ë¬¸êµ¬ '{text}'")
                return ""
        
        # 10. ì˜ì–´ ë‹¨ì–´ ë¹„ìœ¨ ì²´í¬ (ê°„ë‹¨í•œ ì˜ì–´ ë‹¨ì–´ ì‚¬ì „)
        common_english_words = {
            'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by',
            'is', 'are', 'was', 'were', 'be', 'been', 'have', 'has', 'had', 'do', 'does', 'did',
            'will', 'would', 'could', 'should', 'can', 'may', 'might', 'must',
            'i', 'you', 'he', 'she', 'it', 'we', 'they', 'me', 'him', 'her', 'us', 'them',
            'this', 'that', 'these', 'those', 'here', 'there', 'where', 'when', 'why', 'how',
            'falcon', 'runway', 'bird', 'check', 'status', 'risk', 'assessment', 'clear', 'request',
            'alpha', 'bravo', 'charlie', 'delta', 'echo', 'foxtrot', 'golf', 'hotel', 'india',
            'juliet', 'kilo', 'lima', 'mike', 'november', 'oscar', 'papa', 'quebec', 'romeo',
            'sierra', 'tango', 'uniform', 'victor', 'whiskey', 'xray', 'yankee', 'zulu'
        }
        
        words = re.findall(r'\b[a-zA-Z]+\b', text.lower())
        if words:
            english_word_count = sum(1 for word in words if word in common_english_words or len(word) >= 3)
            english_ratio = english_word_count / len(words)
            
            if english_ratio < 0.4:  # ì˜ì–´ ë‹¨ì–´ ë¹„ìœ¨ì„ 40%ë¡œ ìƒí–¥ ì¡°ì •
                print(f"[WhisperSTT] í™˜ê° ê°ì§€: ì˜ì–´ ë‹¨ì–´ ë¹„ìœ¨ ë¶€ì¡± '{text}' (ë¹„ìœ¨: {english_ratio:.2f})")
                return ""
        
        print(f"[WhisperSTT] ìœ íš¨í•œ í…ìŠ¤íŠ¸ ê²€ì¦ í†µê³¼: '{text}'")
        return text
